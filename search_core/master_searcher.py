# search_core/master_searcher.py

from typing import Dict, Any, Optional, List
import os
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm

# Import c√°c module c·ªët l√µi c·ªßa h·ªá th·ªëng
from search_core.basic_searcher import BasicSearcher
from search_core.semantic_searcher import SemanticSearcher
from search_core.trake_solver import TRAKESolver
from search_core.gemini_text_handler import GeminiTextHandler
from search_core.openai_handler import OpenAIHandler
from search_core.task_analyzer import TaskType
from search_core.mmr_builder import MMRResultBuilder 


class MasterSearcher:
    """
    L·ªõp ƒëi·ªÅu ph·ªëi ch√≠nh c·ªßa h·ªá th·ªëng t√¨m ki·∫øm (Hybrid AI Edition).
    N√≥ qu·∫£n l√Ω v√† ƒëi·ªÅu ph·ªëi c√°c AI Handler kh√°c nhau (Gemini cho text, OpenAI cho vision)
    ƒë·ªÉ gi·∫£i quy·∫øt c√°c lo·∫°i truy v·∫•n ph·ª©c t·∫°p.
    """

    def __init__(self, 
                 basic_searcher: BasicSearcher, 
                 gemini_api_key: Optional[str] = None,
                 openai_api_key: Optional[str] = None,
                 entities_path: str = None,
                clip_features_path: str = None): 
        """
        Kh·ªüi t·∫°o MasterSearcher v√† h·ªá sinh th√°i AI lai.
        """
        print("--- üß† Kh·ªüi t·∫°o Master Searcher (Hybrid AI Edition) ---")
        
        self.semantic_searcher = SemanticSearcher(basic_searcher=basic_searcher)
        self.mmr_builder: Optional[MMRResultBuilder] = None
        if clip_features_path and os.path.exists(clip_features_path):
            try:
                all_clip_features = basic_searcher.get_all_clip_features() 
                self.mmr_builder = MMRResultBuilder(clip_features=all_clip_features)
            except Exception as e:
                 print(f"--- ‚ö†Ô∏è L·ªói khi kh·ªüi t·∫°o MMR Builder: {e}. MMR s·∫Ω b·ªã v√¥ hi·ªáu h√≥a. ---")
        else:
            print("--- ‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file CLIP features, MMR s·∫Ω kh√¥ng ho·∫°t ƒë·ªông. ---")

        print(f"--- ‚úÖ Master Searcher ƒë√£ s·∫µn s√†ng! (AI Enabled: {self.ai_enabled}) ---")
        self.gemini_handler: Optional[GeminiTextHandler] = None
        self.openai_handler: Optional[OpenAIHandler] = None
        self.trake_solver: Optional[TRAKESolver] = None
        self.ai_enabled = False
        self.known_entities: set = set()
        
        if entities_path and os.path.exists(entities_path):
            try:
                print(f"--- üìö ƒêang t·∫£i T·ª´ ƒëi·ªÉn ƒê·ªëi t∆∞·ª£ng t·ª´: {entities_path} ---")
                with open(entities_path, 'r') as f:
                    entities_list = [entity.lower() for entity in json.load(f)]
                    self.known_entities = set(entities_list)
                print(f"--- ‚úÖ T·∫£i th√†nh c√¥ng {len(self.known_entities)} th·ª±c th·ªÉ ƒë√£ bi·∫øt. ---")
            except Exception as e:
                print(f"--- ‚ö†Ô∏è L·ªói khi t·∫£i T·ª´ ƒëi·ªÉn ƒê·ªëi t∆∞·ª£ng: {e}. Semantic Grounding s·∫Ω b·ªã v√¥ hi·ªáu h√≥a. ---")
                
        # --- Kh·ªüi t·∫°o v√† x√°c th·ª±c Gemini Handler cho c√°c t√°c v·ª• TEXT ---
        if gemini_api_key:
            try:
                self.gemini_handler = GeminiTextHandler(api_key=gemini_api_key)
                if self.known_entities and self.gemini_handler:
                    self.gemini_handler.load_known_entities(self.known_entities)
                self.ai_enabled = True
            except Exception as e:
                print(f"--- ‚ö†Ô∏è L·ªói khi kh·ªüi t·∫°o Gemini Handler: {e}. C√°c t√≠nh nƒÉng text AI s·∫Ω b·ªã h·∫°n ch·∫ø. ---")

        # --- Kh·ªüi t·∫°o v√† x√°c th·ª±c OpenAI Handler cho c√°c t√°c v·ª• VISION ---
        if openai_api_key:
            try:
                self.openai_handler = OpenAIHandler(api_key=openai_api_key)
                if not self.openai_handler.check_api_health():
                    self.openai_handler = None
                else:
                    self.ai_enabled = True
            except Exception as e:
                print(f"--- ‚ö†Ô∏è L·ªói khi kh·ªüi t·∫°o OpenAI Handler: {e}. C√°c t√≠nh nƒÉng vision AI s·∫Ω b·ªã h·∫°n ch·∫ø. ---")
        
        # --- Kh·ªüi t·∫°o c√°c Solver ph·ª©c t·∫°p n·∫øu c√°c handler c·∫ßn thi·∫øt ƒë√£ s·∫µn s√†ng ---
        if self.gemini_handler:
            self.trake_solver = TRAKESolver(ai_handler=self.gemini_handler)

        print(f"--- ‚úÖ Master Searcher ƒë√£ s·∫µn s√†ng! (AI Enabled: {self.ai_enabled}) ---")

    def search(self, query: str, config: Dict[str, Any]) -> Dict[str, Any]:
        """
        H√†m t√¨m ki·∫øm ch√≠nh, nh·∫≠n m·ªôt dictionary config ƒë·ªÉ t√πy ch·ªânh h√†nh vi.
        """
        # --- B∆∞·ªõc 1: Gi·∫£i n√©n Config ---
        top_k_final = int(config.get('top_k_final', 100))
        kis_retrieval = int(config.get('kis_retrieval', 200))
        vqa_candidates_to_rank = int(config.get('vqa_candidates', 20))
        vqa_retrieval = int(config.get('vqa_retrieval', 200))
        trake_candidates_per_step = int(config.get('trake_candidates_per_step', 20))
        trake_max_sequences = int(config.get('trake_max_sequences', 50))
        w_clip = config.get('w_clip', 0.4)
        w_obj = config.get('w_obj', 0.3)
        w_semantic = config.get('w_semantic', 0.3)
        lambda_mmr = config.get('lambda_mmr', 0.7)

        # --- B∆∞·ªõc 2: Ph√¢n t√≠ch Truy v·∫•n ---
        query_analysis = {}
        task_type = TaskType.KIS
        if self.ai_enabled and self.gemini_handler:
            print("--- ‚ú® B·∫Øt ƒë·∫ßu ph√¢n t√≠ch truy v·∫•n b·∫±ng Gemini Text Handler... ---")
            query_analysis = self.gemini_handler.analyze_query_fully(query)
            
            original_objects = query_analysis.get('objects_en', [])
            if original_objects:
                grounded_objects = self.gemini_handler.perform_semantic_grounding(original_objects)
                if original_objects != grounded_objects:
                     print(f"--- üß† Semantic Grounding: {original_objects} -> {grounded_objects} ---")
                query_analysis['objects_en'] = grounded_objects
                
            task_type_str = query_analysis.get('task_type', 'KIS').upper()
            try:
                task_type = TaskType[task_type_str]
            except KeyError:
                task_type = TaskType.KIS
        
        print(f"--- ƒê√£ ph√¢n lo·∫°i truy v·∫•n l√†: {task_type.value} ---")

        final_results = []
        query_analysis.update({'w_clip': w_clip, 'w_obj': w_obj, 'w_semantic': w_semantic})
        search_context = query_analysis.get('search_context', query)

        # --- B∆∞·ªõc 3: Kh·ªëi ƒêi·ªÅu ph·ªëi Logic ---

        if task_type == TaskType.TRAKE:
            if self.trake_solver:
                sub_queries = self.trake_solver.decompose_query(query)
                final_results = self.trake_solver.find_sequences(
                    sub_queries, 
                    self.semantic_searcher,
                    original_query_analysis=query_analysis,
                    top_k_per_step=trake_candidates_per_step,
                    max_sequences=trake_max_sequences
                )
            else:
                task_type = TaskType.KIS

        elif task_type == TaskType.QNA:
            if self.openai_handler:
                candidates = self.semantic_searcher.search(
                    query_text=search_context,
                    precomputed_analysis=query_analysis,
                    top_k_final=vqa_retrieval,
                    top_k_retrieval=vqa_retrieval
                )
                
                if not candidates:
                    final_results = []
                else:
                    candidates_for_vqa = candidates[:vqa_candidates_to_rank]
                    specific_question = query_analysis.get('specific_question', query)
                    vqa_enhanced_candidates = []
                    
                    print(f"--- üí¨ B·∫Øt ƒë·∫ßu Qu√©t VQA song song tr√™n {len(candidates_for_vqa)} ·ª©ng vi√™n... ---")
                    
                    with ThreadPoolExecutor(max_workers=8) as executor:
                        future_to_candidate = {
                            executor.submit(
                                self.openai_handler.perform_vqa, 
                                image_path=cand['keyframe_path'], 
                                question=specific_question, 
                                context_text=cand.get('transcript_text', '')
                            ): cand 
                            for cand in candidates_for_vqa
                        }
                        
                        for future in tqdm(as_completed(future_to_candidate), total=len(candidates_for_vqa), desc="   -> VQA Progress"):
                            cand = future_to_candidate[future]
                            try:
                                vqa_result = future.result()
                                new_cand = cand.copy()
                                new_cand['answer'] = vqa_result['answer']
                                search_score = new_cand.get('final_score', 0)
                                vqa_confidence = vqa_result.get('confidence', 0)
                                new_cand['final_score'] = search_score * vqa_confidence
                                new_cand['scores']['vqa_confidence'] = vqa_confidence
                                vqa_enhanced_candidates.append(new_cand)
                            except Exception as exc:
                                print(f"--- ‚ùå L·ªói khi x·ª≠ l√Ω VQA cho keyframe {cand.get('keyframe_id')}: {exc} ---")
                    
                    if vqa_enhanced_candidates:
                        final_results = sorted(vqa_enhanced_candidates, key=lambda x: x['final_score'], reverse=True)
                    else:
                        final_results = []
            else:
                print("--- ‚ö†Ô∏è OpenAI (VQA) handler ch∆∞a ƒë∆∞·ª£c k√≠ch ho·∫°t. Fallback v·ªÅ KIS. ---")
                task_type = TaskType.KIS

        if not final_results or task_type == TaskType.KIS:
            final_results = self.semantic_searcher.search(
                query_text=search_context,
                precomputed_analysis=query_analysis,
                top_k_final=kis_retrieval, 
                top_k_retrieval=kis_retrieval
            )
        # --- B∆Ø·ªöC 4: √ÅP D·ª§NG MMR ƒê·ªÇ TƒÇNG C∆Ø·ªúNG ƒêA D·∫†NG ---
        diverse_results = final_results
        if self.mmr_builder and final_results:
            # L∆∞u √Ω quan tr·ªçng: TRAKE tr·∫£ v·ªÅ danh s√°ch c√°c chu·ªói, kh√¥ng ph·∫£i c√°c frame ƒë∆°n l·∫ª.
            # MMR ch·ªâ n√™n √°p d·ª•ng cho KIS v√† QNA.
            if task_type in [TaskType.KIS, TaskType.QNA]:
                diverse_results = self.mmr_builder.build_diverse_list(
                    candidates=final_results, 
                    target_size=len(final_results), # MMR s·∫Ω s·∫Øp x·∫øp l·∫°i to√†n b·ªô list
                    lambda_val=lambda_mmr
                )

        # T·∫°m th·ªùi ch·ªâ c·∫Øt b·ªõt
        final_results_for_submission = diverse_results[:top_k_final]

        # *** LOG DEBUG ƒêI·ªÇM A ***
        print("\n" + "="*20 + " DEBUG LOG: MASTER SEARCHER OUTPUT " + "="*20)
        print(f"-> Task Type cu·ªëi c√πng: {task_type.value}")
        print(f"-> S·ªë l∆∞·ª£ng k·∫øt qu·∫£ cu·ªëi c√πng: {len(final_results)}")
        if final_results:
            print("-> V√≠ d·ª• k·∫øt qu·∫£ ƒë·∫ßu ti√™n:")
            first_result = final_results[0]
            if task_type == TaskType.TRAKE:
                print(f"  - video_id: {first_result.get('video_id')}")
                print(f"  - final_score: {first_result.get('final_score')}")
                print(f"  - S·ªë b∆∞·ªõc trong chu·ªói: {len(first_result.get('sequence', []))}")
            else: # KIS, QNA
                print(f"  - keyframe_id: {first_result.get('keyframe_id')}")
                print(f"  - final_score: {first_result.get('final_score')}")
                if 'answer' in first_result:
                    print(f"  - answer: {first_result.get('answer')}")
        else:
            print("-> Kh√¥ng c√≥ k·∫øt qu·∫£ n√†o ƒë∆∞·ª£c t·∫°o ra.")
        print("="*68 + "\n")
        
        return {
            "task_type": task_type,
            "results": final_results_for_submission,
            "query_analysis": query_analysis
        }