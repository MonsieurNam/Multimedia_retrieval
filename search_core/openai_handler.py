# /kaggle/working/search_core/openai_handler.py

import openai
import json
import re
import base64
from typing import Dict, Any, List, Optional

from utils import api_retrier

class OpenAIHandler:
    """
    Má»™t class "adapter" Ä‘á»ƒ Ä‘Ã³ng gÃ³i táº¥t cáº£ cÃ¡c lá»‡nh gá»i API Ä‘áº¿n OpenAI.
    Che giáº¥u sá»± phá»©c táº¡p cá»§a viá»‡c gá»i API vÃ  cung cáº¥p cÃ¡c phÆ°Æ¡ng thá»©c
    rÃµ rÃ ng cho cÃ¡c tÃ¡c vá»¥ cá»¥ thá»ƒ (phÃ¢n tÃ­ch, VQA, etc.).
    """
    def __init__(self, api_key: str, model: str = "gpt-4o-mini"):
        """
        Khá»Ÿi táº¡o OpenAI Handler.

        Args:
            api_key (str): OpenAI API key.
            model (str): TÃªn model máº·c Ä‘á»‹nh cho cÃ¡c tÃ¡c vá»¥ text.
                         GPT-4o-mini lÃ  má»™t lá»±a chá»n tá»‘t vá» tá»‘c Ä‘á»™ vÃ  chi phÃ­.
        """
        print(f"--- ðŸ¤– Khá»Ÿi táº¡o OpenAI Handler vá»›i model máº·c Ä‘á»‹nh: {model} ---")
        self.client = openai.OpenAI(api_key=api_key)
        self.model = model
        # GPT-4o lÃ  model vision máº¡nh máº½ nháº¥t hiá»‡n táº¡i cá»§a OpenAI
        self.vision_model = "gpt-4o"
        
    @api_retrier(max_retries=2, initial_delay=1)
    def check_api_health(self) -> bool:
        """
        Thá»±c hiá»‡n má»™t lá»‡nh gá»i API Ä‘Æ¡n giáº£n Ä‘á»ƒ kiá»ƒm tra xem API key cÃ³ há»£p lá»‡ vÃ  hoáº¡t Ä‘á»™ng khÃ´ng.
        
        Sá»­ dá»¥ng viá»‡c táº¡o embedding cho má»™t tá»« ngáº¯n, Ä‘Ã¢y lÃ  má»™t API call nháº¹ vÃ  ráº».

        Returns:
            bool: True náº¿u API hoáº¡t Ä‘á»™ng, False náº¿u khÃ´ng.
        """
        print("--- ðŸ©º Äang thá»±c hiá»‡n kiá»ƒm tra tráº¡ng thÃ¡i API OpenAI... ---")
        try:
            # text-embedding-ada-002 hoáº·c text-embedding-3-small lÃ  lá»±a chá»n tá»‘t
            self.client.embeddings.create(
                input="kiá»ƒm tra",
                model="text-embedding-3-small"
            )
            print("--- âœ… Tráº¡ng thÃ¡i API OpenAI: OK ---")
            return True
        except openai.AuthenticationError as e:
            # Lá»—i nÃ y Ä‘áº·c trÆ°ng cho API key sai hoáº·c khÃ´ng há»£p lá»‡
            print(f"--- âŒ Lá»—i OpenAI API: Authentication Error. API Key cÃ³ thá»ƒ khÃ´ng há»£p lá»‡. Lá»—i: {e} ---")
            return False
        except Exception as e:
            # Báº¯t cÃ¡c lá»—i khÃ¡c (máº¡ng, etc.)
            print(f"--- âŒ Lá»—i OpenAI API: KhÃ´ng thá»ƒ káº¿t ná»‘i Ä‘áº¿n OpenAI. Lá»—i: {e} ---")
            return False

    @api_retrier(max_retries=3, initial_delay=2)
    def _openai_vision_call(self, messages: List[Dict], is_json: bool = True, is_vision: bool = False) -> Optional[str]: # ThÃªm Optional[str]
        """
        HÃ m con chung Ä‘á»ƒ thá»±c hiá»‡n cÃ¡c lá»‡nh gá»i API chat completion.
        *** PHIÃŠN Báº¢N AN TOÃ€N HÆ N ***
        """
        model_to_use = self.vision_model if is_vision else self.model
        response_format = {"type": "json_object"} if is_json else {"type": "text"}
        
        response = self.client.chat.completions.create(
            model=model_to_use,
            messages=messages,
            response_format=response_format,
            temperature=0.1,
            max_tokens=1024
        )
        
        # --- THÃŠM KIá»‚M TRA Táº I ÄÃ‚Y ---
        if response.choices and response.choices[0].message:
            content = response.choices[0].message.content
            # Tráº£ vá» chuá»—i rá»—ng náº¿u content lÃ  None, thay vÃ¬ tráº£ vá» chÃ­nh None
            return content if content is not None else "" 
        
        # Náº¿u khÃ´ng cÃ³ choices hoáº·c message, tráº£ vá» chuá»—i rá»—ng
        return ""

    def _encode_image_to_base64(self, image_path: str) -> str:
        """MÃ£ hÃ³a má»™t file áº£nh thÃ nh chuá»—i base64."""
        try:
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
        except Exception as e:
            print(f"--- âš ï¸ Lá»—i khi mÃ£ hÃ³a áº£nh {image_path}: {e} ---")
            return ""

    def enhance_query(self, query: str) -> Dict[str, Any]:
        """
        PhÃ¢n tÃ­ch, tÄƒng cÆ°á»ng vÃ  dá»‹ch truy váº¥n cá»§a ngÆ°á»i dÃ¹ng.
        """
        fallback_result = {'search_context': query, 'specific_question': "", 'objects_vi': [], 'objects_en': []}
        prompt = f"""
        Analyze a Vietnamese user query for a video search system. **Return ONLY a valid JSON object** with: "search_context", "specific_question", "objects_vi", and "objects_en".

        Rules:
        - "search_context": A Vietnamese phrase for finding the scene.
        - "specific_question": The specific question. For KIS queries, this is an empty string "".
        - "objects_vi": A list of Vietnamese nouns/entities.
        - "objects_en": The English translation for EACH item in "objects_vi". The two lists must have the same length.

        Example (VQA):
        Query: "Trong video quay cáº£nh bá»¯a tiá»‡c, ngÆ°á»i phá»¥ ná»¯ máº·c vÃ¡y Ä‘á» Ä‘ang cáº§m ly mÃ u gÃ¬?"
        JSON: {{"search_context": "cáº£nh bá»¯a tiá»‡c cÃ³ ngÆ°á»i phá»¥ ná»¯ máº·c vÃ¡y Ä‘á»", "specific_question": "cÃ´ áº¥y Ä‘ang cáº§m ly mÃ u gÃ¬?", "objects_vi": ["bá»¯a tiá»‡c", "ngÆ°á»i phá»¥ ná»¯", "vÃ¡y Ä‘á»"], "objects_en": ["party", "woman", "red dress"]}}

        Query: "{query}"
        JSON:
        """
        try:
            response_content = self._openai_chat_completion([{"role": "user", "content": prompt}], is_json=True)
            result = json.loads(response_content)
            # Validate...
            if all(k in result for k in ['search_context', 'specific_question', 'objects_vi', 'objects_en']):
                return result
            return fallback_result
        except Exception as e:
            print(f"Lá»—i OpenAI enhance_query: {e}")
            return fallback_result

    def analyze_task_type(self, query: str) -> str:
        """
        PhÃ¢n loáº¡i truy váº¥n vá»›i Quy táº¯c Æ¯u tiÃªn Ä‘á»ƒ xá»­ lÃ½ cÃ¡c trÆ°á»ng há»£p lai.
        """
        prompt = f"""
        You are a highly precise query classifier. Your task is to classify a Vietnamese query into one of four categories: TRACK_VQA, TRAKE, QNA, or KIS. You MUST follow a strict priority order.

        **Priority Order for Classification (Check from top to bottom):**

        1.  **Check for TRACK_VQA first:** Does the query ask a question about a COLLECTION of items, requiring aggregation (counting, listing, summarizing)? Look for keywords like "Ä‘áº¿m", "bao nhiÃªu", "liá»‡t kÃª", "táº¥t cáº£", "má»—i", or plural subjects. If it matches, classify as **TRACK_VQA** and stop.
            - Example: "trong buá»•i trÃ¬nh diá»…n mÃºa lÃ¢n, Ä‘áº¿m xem cÃ³ bao nhiÃªu con lÃ¢n" -> This is a request to count a collection, so it is **TRACK_VQA**.

        2.  **Then, check for TRAKE:** If it's not TRACK_VQA, does the query ask for a SEQUENCE of DIFFERENT, ordered actions? Look for patterns like "(1)...(2)...", "bÆ°á»›c 1... bÆ°á»›c 2", "sau Ä‘Ã³". If it matches, classify as **TRAKE** and stop.
            - Example: "ngÆ°á»i Ä‘Ã n Ã´ng Ä‘á»©ng lÃªn rá»“i bÆ°á»›c Ä‘i"

        3.  **Then, check for QNA:** If it's not TRACK_VQA or TRAKE, is it a direct question about a SINGLE item? Look for a question mark "?" or interrogative words like "cÃ¡i gÃ¬", "ai". If it matches, classify as **QNA** and stop.
            - Example: "ngÆ°á»i phá»¥ ná»¯ máº·c Ã¡o mÃ u gÃ¬?"

        4.  **Default to KIS:** If the query does not meet any of the criteria above, it is a simple description of a scene. Classify as **KIS**.
            - Example: "cáº£nh mÃºa lÃ¢n"

        **Your Task:**
        Follow the priority order strictly. Analyze the query below and return ONLY the final category as a single word.

        **Query:** "{query}"
        **Category:**
        """
        try:
            # Sá»­ dá»¥ng hÃ m chat completion Ä‘Ã£ cÃ³
            response = self._openai_chat_completion([{"role": "user", "content": prompt}], is_json=False)
            task_type = response.strip().upper()
            
            # Kiá»ƒm tra xem káº¿t quáº£ tráº£ vá» cÃ³ há»£p lá»‡ khÃ´ng
            if task_type in ["KIS", "QNA", "TRAKE", "TRACK_VQA"]:
                print(f"--- âœ… PhÃ¢n loáº¡i truy váº¥n (OpenAI): '{query}' -> {task_type} ---")
                return task_type
                
            print(f"--- âš ï¸ PhÃ¢n loáº¡i khÃ´ng há»£p lá»‡ tá»« OpenAI: '{task_type}'. Fallback vá» Heuristic. ---")
            return self._analyze_query_heuristic_fallback(query) # Váº«n giá»¯ fallback

        except Exception as e:
            print(f"Lá»—i OpenAI analyze_task_type: {e}. Fallback vá» Heuristic.")
            return self._analyze_query_heuristic_fallback(query)

    # Cáº­p nháº­t hÃ m fallback heuristic Ä‘á»ƒ nÃ³ khÃ´ng bao giá» tráº£ vá» TRACK_VQA
    def _analyze_query_heuristic_fallback(self, query: str) -> str:
        """
        HÃ m heuristic dá»± phÃ²ng. Sáº½ khÃ´ng phÃ¢n loáº¡i TRACK_VQA, Ä‘á»ƒ an toÃ n.
        """
        query_lower = query.lower().strip()
        qna_keywords = ['mÃ u gÃ¬', 'ai lÃ ', 'ai Ä‘ang', 'á»Ÿ Ä‘Ã¢u', 'khi nÃ o', 'táº¡i sao', 'cÃ¡i gÃ¬', 'bao nhiÃªu']
        if '?' in query or any(query_lower.startswith(k) for k in qna_keywords):
            # LÆ°u Ã½: "bao nhiÃªu" cÃ³ thá»ƒ lÃ  TRACK_VQA, nhÆ°ng trong heuristic ta Æ°u tiÃªn QNA cho an toÃ n
            return "QNA"
        trake_pattern = r'\(\d+\)|bÆ°á»›c \d+|\d\.'
        if re.search(trake_pattern, query_lower) or "tÃ¬m cÃ¡c khoáº£nh kháº¯c" in query_lower:
            return "TRAKE"
        return "KIS"

    def perform_vqa(self, image_path: str, question: str) -> Dict[str, any]:
        """
        Thá»±c hiá»‡n VQA sá»­ dá»¥ng GPT-4o.
        *** PHIÃŠN Báº¢N CÃ“ Xá»¬ LÃ Lá»–I Tá»T HÆ N ***
        """
        base64_image = self._encode_image_to_base64(image_path)
        if not base64_image:
            return {"answer": "Lá»—i: KhÃ´ng thá»ƒ xá»­ lÃ½ áº£nh", "confidence": 0.0}

        prompt = f"""
        You are a Visual Question Answering assistant. Based on the provided image, answer the user's question.
        
        **Your task is to return ONLY a valid JSON object** with two keys: "answer" and "confidence".
        - "answer": A short, direct answer in Vietnamese.
        - "confidence": Your confidence in the answer, from 0.0 (very unsure) to 1.0 (certain).

        **User's Question:** "{question}"
        """
        
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"},
                    },
                ],
            }
        ]
        try:
            response_content = self._openai_chat_completion(messages, is_json=True, is_vision=True)
            
            if not response_content:
                print("--- âš ï¸ OpenAI VQA khÃ´ng tráº£ vá» ná»™i dung. ---")
                return {"answer": "KhÃ´ng thá»ƒ phÃ¢n tÃ­ch hÃ¬nh áº£nh", "confidence": 0.1}

            result = json.loads(response_content)
            return {
                "answer": result.get("answer", "KhÃ´ng cÃ³ cÃ¢u tráº£ lá»i"),
                "confidence": float(result.get("confidence", 0.5))
            }
        except (json.JSONDecodeError, TypeError) as e:
             # Báº¯t cáº£ lá»—i TypeError tá»« json.loads(None) vÃ  JSONDecodeError
            print(f"Lá»—i OpenAI perform_vqa (JSON parsing): {e}. Response nháº­n Ä‘Æ°á»£c: '{response_content}'")
            return {"answer": "Lá»—i Ä‘á»‹nh dáº¡ng pháº£n há»“i", "confidence": 0.0}
        except Exception as e:
            print(f"Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh trong OpenAI perform_vqa: {e}")
            return {"answer": "Lá»—i xá»­ lÃ½ VQA", "confidence": 0.0}

    def decompose_trake_query(self, query: str) -> List[str]:
        """PhÃ¢n rÃ£ truy váº¥n TRAKE thÃ nh cÃ¡c bÆ°á»›c con."""
        prompt = f"""
        Decompose the Vietnamese query describing a sequence of actions into a JSON array of short, self-contained phrases. Return ONLY the JSON array.

        Example:
        Query: "TÃ¬m 4 khoáº£nh kháº¯c chÃ­nh khi váº­n Ä‘á»™ng viÃªn thá»±c hiá»‡n cÃº nháº£y: (1) giáº­m nháº£y, (2) bay qua xÃ , (3) tiáº¿p Ä‘áº¥t, (4) Ä‘á»©ng dáº­y."
        JSON: ["váº­n Ä‘á»™ng viÃªn giáº­m nháº£y", "váº­n Ä‘á»™ng viÃªn bay qua xÃ ", "váº­n Ä‘á»™ng viÃªn tiáº¿p Ä‘áº¥t", "váº­n Ä‘á»™ng viÃªn Ä‘á»©ng dáº­y"]

        Query: "{query}"
        JSON:
        """
        try:
            response_content = self._openai_chat_completion([{"role": "user", "content": prompt}], is_json=True)
            result = json.loads(response_content)
            if isinstance(result, list):
                return result
            return [query] # Fallback
        except Exception as e:
            print(f"Lá»—i OpenAI decompose_trake_query: {e}")
            return [query]