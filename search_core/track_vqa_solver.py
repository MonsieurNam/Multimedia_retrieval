from typing import List, Dict, Any

# Import c√°c th√†nh ph·∫ßn c·∫ßn thi·∫øt ƒë·ªÉ type hinting
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from search_core.openai_handler import OpenAIHandler
    from search_core.semantic_searcher import SemanticSearcher
    from search_core.gemini_text_handler import GeminiTextHandler

import time

class TrackVQASolver:
    """
    Class x·ª≠ l√Ω t√°c v·ª• "Theo d√µi v√† T·ªïng h·ª£p Th√¥ng tin" (Track-VQA).

    ƒê√¢y l√† m·ªôt pipeline ph·ª©c t·∫°p bao g·ªìm c√°c b∆∞·ªõc:
    1.  Truy xu·∫•t h√†ng lo·∫°t c√°c kho·∫£nh kh·∫Øc ·ª©ng vi√™n d·ª±a tr√™n b·ªëi c·∫£nh.
    2.  (T∆∞∆°ng lai) L·ªçc v√† gom c·ª•m ƒë·ªÉ t√¨m c√°c kho·∫£nh kh·∫Øc ƒë·ªôc nh·∫•t.
    3.  Th·ª±c hi·ªán VQA tr√™n t·ª´ng kho·∫£nh kh·∫Øc ƒë·ªÉ thu th·∫≠p "b·∫±ng ch·ª©ng".
    4.  S·ª≠ d·ª•ng AI ƒë·ªÉ t·ªïng h·ª£p t·∫•t c·∫£ b·∫±ng ch·ª©ng th√†nh m·ªôt c√¢u tr·∫£ l·ªùi cu·ªëi c√πng.
    """

    def __init__(self, 
                 text_handler: 'GeminiTextHandler', 
                 vision_handler: 'OpenAIHandler', 
                 semantic_searcher: 'SemanticSearcher'):
        """
        Kh·ªüi t·∫°o TrackVQASolver.

        Args:
            text_handler (GeminiTextHandler): Handler ƒë·ªÉ th·ª±c hi·ªán c√°c t√°c v·ª• text (ph√¢n t√≠ch).
            vision_handler (OpenAIHandler): Handler ƒë·ªÉ th·ª±c hi·ªán c√°c t√°c v·ª• vision (VQA l·∫∑p l·∫°i).
            semantic_searcher (SemanticSearcher): Searcher ƒë·ªÉ truy xu·∫•t c√°c kho·∫£nh kh·∫Øc.
        """
        # ƒê·ªïi t√™n self.ai_handler th√†nh c√°c t√™n c·ª• th·ªÉ h∆°n
        self.text_handler = text_handler
        self.vision_handler = vision_handler
        self.searcher = semantic_searcher


    def solve(self, query_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        Th·ª±c thi to√†n b·ªô pipeline Track-VQA.

        Args:
            query_analysis (Dict[str, Any]): Dictionary k·∫øt qu·∫£ ph√¢n t√≠ch t·ª´ AI Handler.

        Returns:
            Dict[str, Any]: M·ªôt dictionary ch·ª©a c√¢u tr·∫£ l·ªùi cu·ªëi c√πng v√† c√°c frame b·∫±ng ch·ª©ng.
        """
        print("--- üî¨ B·∫Øt ƒë·∫ßu pipeline Track-VQA ---")
        
        # --- 1. Truy xu·∫•t c√°c kho·∫£nh kh·∫Øc ·ª©ng vi√™n ---
        search_context = query_analysis.get('search_context')
        if not search_context:
            return {"final_answer": "L·ªói: Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c b·ªëi c·∫£nh t√¨m ki·∫øm.", "evidence_frames": []}

        print(f"   -> 1/4: ƒêang truy xu·∫•t c√°c kho·∫£nh kh·∫Øc cho context: '{search_context}'")
        # L·∫•y m·ªôt l∆∞·ª£ng l·ªõn ·ª©ng vi√™n ƒë·ªÉ tƒÉng ƒë·ªô bao ph·ªß
        candidates = self.searcher.search(
            query_text=search_context, 
            precomputed_analysis=query_analysis,
            top_k_final=50, # L·∫•y 50 ·ª©ng vi√™n t·ªët nh·∫•t ƒë·ªÉ ph√¢n t√≠ch
            top_k_retrieval=300
        )
        if not candidates:
             return {"final_answer": "Kh√¥ng t√¨m th·∫•y kho·∫£nh kh·∫Øc n√†o ph√π h·ª£p.", "evidence_frames": []}

        # --- 2. L·ªçc v√† Gom c·ª•m (TODO trong t∆∞∆°ng lai) ---
        # Hi·ªán t·∫°i, ch√∫ng ta s·∫Ω x·ª≠ l√Ω 10 ·ª©ng vi√™n h√†ng ƒë·∫ßu ƒë·ªÉ c√¢n b·∫±ng t·ªëc ƒë·ªô v√† ƒë·ªô ch√≠nh x√°c
        moments_to_analyze = candidates[:10]
        print(f"   -> 2/4: ƒê√£ ch·ªçn ra {len(moments_to_analyze)} kho·∫£nh kh·∫Øc h√†ng ƒë·∫ßu ƒë·ªÉ th·ª±c hi·ªán VQA.")

        # --- 3. Th·ª±c hi·ªán VQA l·∫∑p l·∫°i tr√™n t·ª´ng kho·∫£nh kh·∫Øc ---
        specific_question = query_analysis.get('specific_question')
        if not specific_question:
            return {"final_answer": "L·ªói: Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c c√¢u h·ªèi c·ª• th·ªÉ ƒë·ªÉ ph√¢n t√≠ch.", "evidence_frames": []}
            
        print(f"   -> 3/4: ƒêang th·ª±c hi·ªán VQA l·∫∑p l·∫°i v·ªõi c√¢u h·ªèi: '{specific_question}'")
        instance_answers = []
        for moment in moments_to_analyze:
            # Ch√∫ng ta c√≥ th·ªÉ th√™m m·ªôt kho·∫£ng ch·ªù nh·ªè ·ªü ƒë√¢y ƒë·ªÉ tr√°nh rate limit
            time.sleep(0.5) 
            vqa_result = self.vision_handler.perform_vqa(moment['keyframe_path'], specific_question)
            
            # Ch·ªâ thu th·∫≠p c√°c c√¢u tr·∫£ l·ªùi c√≥ ƒë·ªô t·ª± tin cao ƒë·ªÉ tr√°nh "nhi·ªÖu"
            if vqa_result['confidence'] > 0.6:
                instance_answers.append(vqa_result['answer'])

        if not instance_answers:
            return {"final_answer": "Kh√¥ng th·ªÉ thu th·∫≠p ƒë·ªß th√¥ng tin t·ª´ c√°c kho·∫£nh kh·∫Øc t√¨m th·∫•y.", "evidence_frames": candidates[:5]}

        # --- 4. T·ªïng h·ª£p c√°c c√¢u tr·∫£ l·ªùi th√†nh m·ªôt k·∫øt qu·∫£ duy nh·∫•t ---
        aggregation_instruction = query_analysis.get('aggregation_instruction')
        if not aggregation_instruction:
            return {"final_answer": "L·ªói: Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c c√°ch t·ªïng h·ª£p k·∫øt qu·∫£.", "evidence_frames": []}

        print(f"   -> 4/4: ƒêang t·ªïng h·ª£p {len(instance_answers)} c√¢u tr·∫£ l·ªùi...")
        final_answer = self.aggregate_answers(instance_answers, aggregation_instruction)
        
        print(f"--- ‚úÖ Pipeline Track-VQA ho√†n t·∫•t! ---")
        
        return {
            "final_answer": final_answer,
            "evidence_frames": candidates[:5] # Lu√¥n tr·∫£ v·ªÅ 5 frame b·∫±ng ch·ª©ng t·ªët nh·∫•t
        }

    def aggregate_answers(self, answers: List[str], instruction: str) -> str:
        """
        S·ª≠ d·ª•ng AI ƒë·ªÉ t·ªïng h·ª£p m·ªôt danh s√°ch c√°c c√¢u tr·∫£ l·ªùi ri√™ng l·∫ª.
        ƒê√¢y l√† b∆∞·ªõc suy lu·∫≠n cu·ªëi c√πng.

        Args:
            answers (List[str]): Danh s√°ch c√°c c√¢u tr·∫£ l·ªùi t·ª´ VQA tr√™n t·ª´ng frame.
            instruction (str): H∆∞·ªõng d·∫´n c√°ch t·ªïng h·ª£p (v√≠ d·ª•: "ƒë·∫øm v√† li·ªát k√™ m√†u").

        Returns:
            str: C√¢u tr·∫£ l·ªùi t·ªïng h·ª£p cu·ªëi c√πng.
        """
        # Chuy·ªÉn danh s√°ch th√†nh m·ªôt chu·ªói d·ªÖ ƒë·ªçc cho AI
        formatted_answers = "\n".join([f"- {ans}" for ans in answers])
        
        prompt = f"""
        You are a data synthesis AI. Your task is to analyze a list of individual observations from different video frames and synthesize them into a single, final answer based on the user's ultimate goal. Be concise and directly answer the user's original intent.

        **Individual Observations:**
        {formatted_answers}

        **User's Final Goal:**
        "{instruction}"

        **Synthesized Final Answer (in Vietnamese):**
        """
        
        # G·ªçi API c·ªßa ai_handler ƒë·ªÉ nh·∫≠n c√¢u tr·∫£ l·ªùi t·ªïng h·ª£p
        # ·ªû ƒë√¢y, ch√∫ng ta kh√¥ng c·∫ßn JSON
        try:
            response = self.text_handler._gemini_text_call([{"role": "user", "content": prompt}], is_json=False)
            return response.text if hasattr(response, 'text') else str(response)
        except Exception as e:
            print(f"--- ‚ö†Ô∏è L·ªói khi t·ªïng h·ª£p c√¢u tr·∫£ l·ªùi: {e} ---")
            return "Kh√¥ng th·ªÉ t·ªïng h·ª£p k·∫øt qu·∫£."