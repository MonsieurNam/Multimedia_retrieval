import pandas as pd
import faiss
from sentence_transformers import SentenceTransformer, util
import numpy as np
import json
import re
import torch
from tqdm import tqdm
from typing import Dict, List, Optional, Any

# Import BasicSearcher ƒë·ªÉ s·ª≠ d·ª•ng l√†m n·ªÅn t·∫£ng
from search_core.basic_searcher import BasicSearcher

# Import th∆∞ vi·ªán Gemini v√† decorator retrier
import google.generativeai as genai

class SemanticSearcher:
    # --- THAY ƒê·ªîI __init__ ---
    def __init__(self, 
                 basic_searcher: BasicSearcher, 
                 device: str = "cuda"):
        """
        Kh·ªüi t·∫°o SemanticSearcher.
        N√≥ kh√¥ng c√≤n qu·∫£n l√Ω model AI n·ªØa.
        """
        print("--- üß† Kh·ªüi t·∫°o SemanticSearcher (Reranking Engine) ---")
        self.device = device
        self.basic_searcher = basic_searcher
        
        print("   -> ƒêang t·∫£i m√¥ h√¨nh Bi-Encoder ti·∫øng Vi·ªát...")
        self.semantic_model = SentenceTransformer(
            'bkai-foundation-models/vietnamese-bi-encoder', 
            device=self.device
        )
        print("--- ‚úÖ T·∫£i model Bi-Encoder th√†nh c√¥ng! ---")

    def search(self, 
            query_text: str, 
            top_k_final: int = 12, 
            top_k_retrieval: int = 100, 
            precomputed_analysis: Optional[Dict] = None
            ) -> List[Dict[str, Any]]:
        """
        Th·ª±c hi·ªán pipeline t√¨m ki·∫øm ng·ªØ nghƒ©a ho√†n ch·ªânh cho m·ªôt context.
        *** PHI√äN B·∫¢N T·ªêI ∆ØU H√ìA: T·∫Øt progress bar v√† m√£ h√≥a object theo batch ***

        Args:
            query_text (str): B·ªëi c·∫£nh t√¨m ki·∫øm (search_context).
            top_k_final (int): S·ªë k·∫øt qu·∫£ cu·ªëi c√πng tr·∫£ v·ªÅ.
            top_k_retrieval (int): S·ªë ·ª©ng vi√™n ban ƒë·∫ßu ƒë∆∞·ª£c l·∫•y t·ª´ FAISS.
            precomputed_analysis (Optional[Dict]): K·∫øt qu·∫£ ph√¢n t√≠ch Gemini ƒë√£ ƒë∆∞·ª£c t√≠nh to√°n tr∆∞·ªõc.

        Returns:
            List[Dict[str, Any]]: Danh s√°ch c√°c keyframe k·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c x·∫øp h·∫°ng.
        """
        print(f"\n--- B·∫Øt ƒë·∫ßu Semantic Search cho context: '{query_text}' ---")
        
        # --- B∆∞·ªõc 1: Truy xu·∫•t ·ª©ng vi√™n b·∫±ng CLIP ---
        candidates = self.basic_searcher.search(query_text, top_k=top_k_retrieval)
        if not candidates:
            print("-> Kh√¥ng t√¨m th·∫•y ·ª©ng vi√™n n√†o.")
            return []

        # --- B∆∞·ªõc 2: L·∫•y th√¥ng tin Ph√¢n t√≠ch & TƒÉng c∆∞·ªùng ---
        if precomputed_analysis:
            enhanced_query = precomputed_analysis
        else:
            enhanced_query = self.enhance_query_with_gemini(query_text)
        
        rerank_keywords_en = enhanced_query.get('objects_en', [])
        rerank_context_vi = enhanced_query.get('search_context', query_text).lower().strip()
        
        # --- B∆∞·ªõc 3: T√°i x·∫øp h·∫°ng (Reranking) ---

        # --- 3a. M√£ h√≥a Context v√† Transcript (theo batch) ---
        context_vector = self.semantic_model.encode(rerank_context_vi, convert_to_tensor=True, device=self.device)
        candidate_texts = [cand.get('searchable_text', '') for cand in candidates]
        candidate_vectors = self.semantic_model.encode(
            candidate_texts, 
            convert_to_tensor=True, 
            device=self.device, 
            batch_size=128, 
            show_progress_bar=False # T·∫ÆT THANH TI·∫æN TR√åNH
        )
        semantic_scores_tensor = util.pytorch_cos_sim(context_vector, candidate_vectors)[0]

        # --- 3b. M√£ h√≥a Object (t·ªëi ∆∞u h√≥a theo batch) ---
        # Gom t·∫•t c·∫£ c√°c object t·ª´ t·∫•t c·∫£ c√°c ·ª©ng vi√™n l·∫°i
        all_detected_objects = []
        cand_object_indices = [] # L∆∞u l·∫°i index (start, end) ƒë·ªÉ map k·∫øt qu·∫£ v·ªÅ
        for cand in candidates:
            detected_objects_en_raw = cand.get('objects_detected', [])
            # Chuy·ªÉn ƒë·ªïi an to√†n sang list
            detected_objects_en = list(detected_objects_en_raw) if isinstance(detected_objects_en_raw, np.ndarray) else list(detected_objects_en_raw)
            
            start_index = len(all_detected_objects)
            all_detected_objects.extend(detected_objects_en)
            end_index = len(all_detected_objects)
            cand_object_indices.append((start_index, end_index))

        # M√£ h√≥a t·∫•t c·∫£ c√°c object trong m·ªôt l·∫ßn duy nh·∫•t
        all_object_vectors = None
        if all_detected_objects:
            all_object_vectors = self.semantic_model.encode(
                all_detected_objects, 
                convert_to_tensor=True, 
                device=self.device, 
                batch_size=256, 
                show_progress_bar=False # T·∫ÆT THANH TI·∫æN TR√åNH
            )

        # M√£ h√≥a object c·ªßa truy v·∫•n m·ªôt l·∫ßn
        query_object_vectors = None
        if rerank_keywords_en:
            query_object_vectors = self.semantic_model.encode(
                rerank_keywords_en, convert_to_tensor=True, device=self.device)

        # --- 3c. T√≠nh to√°n ƒëi·ªÉm cu·ªëi c√πng cho m·ªói ·ª©ng vi√™n ---
        reranked_results = []
        for i, cand in enumerate(candidates):
            # T√≠nh Object Score
            object_score = 0.0
            start, end = cand_object_indices[i]
            
            # L·∫•y c√°c vector ƒë√£ ƒë∆∞·ª£c t√≠nh to√°n tr∆∞·ªõc, kh√¥ng c·∫ßn encode l·∫°i
            if query_object_vectors is not None and start < end and all_object_vectors is not None:
                detected_object_vectors = all_object_vectors[start:end]
                cosine_scores = util.pytorch_cos_sim(query_object_vectors, detected_object_vectors)
                if cosine_scores.numel() > 0:
                    max_scores_per_query_obj = torch.max(cosine_scores, dim=1).values
                    object_score = torch.mean(max_scores_per_query_obj).item()

            # T√≠nh Semantic Score
            semantic_score = (semantic_scores_tensor[i].item() + 1) / 2
            
            # T√≠nh Final Score
            w_clip, w_obj, w_semantic = 0.4, 0.3, 0.3
            normalized_clip_score = cand['clip_score']
            
            final_score = (w_clip * normalized_clip_score + 
                        w_obj * object_score + 
                        w_semantic * semantic_score)
            
            cand['final_score'] = final_score
            cand['scores'] = {'clip': normalized_clip_score, 'object': object_score, 'semantic': semantic_score}
            reranked_results.append(cand)

        # S·∫Øp x·∫øp l·∫°i d·ª±a tr√™n ƒëi·ªÉm cu·ªëi c√πng v√† tr·∫£ v·ªÅ
        reranked_results = sorted(reranked_results, key=lambda x: x['final_score'], reverse=True)
        print(f"--- ‚úÖ T√°i x·∫øp h·∫°ng cho context '{query_text}' ho√†n t·∫•t! ---")
        
        return reranked_results[:top_k_final]