from typing import Dict, Any, Optional
import google.generativeai as genai
from google.api_core import exceptions as google_exceptions # Import ƒë·ªÉ b·∫Øt l·ªói c·ª• th·ªÉ

# Import c√°c module c·ªët l√µi c·ªßa h·ªá th·ªëng
from .task_analyzer import TaskType, analyze_query_gemini, analyze_query_heuristic
from .semantic_searcher import SemanticSearcher
from .vqa_handler import VQAHandler
from .trake_solver import TRAKESolver
from ..utils import gemini_api_retrier # Import retrier

class MasterSearcher:
    """
    L·ªõp ƒëi·ªÅu ph·ªëi ch√≠nh c·ªßa h·ªá th·ªëng t√¨m ki·∫øm.
    """

    def __init__(self, 
                 semantic_searcher: SemanticSearcher, 
                 gemini_api_key: Optional[str] = None):
        """
        Kh·ªüi t·∫°o MasterSearcher v√† t·∫•t c·∫£ c√°c th√†nh ph·∫ßn con c·ªßa n√≥.
        """
        print("--- üß† Kh·ªüi t·∫°o Master Searcher ---")
        
        self.semantic_searcher = semantic_searcher
        self.gemini_model: Optional[genai.GenerativeModel] = None
        self.vqa_handler: Optional[VQAHandler] = None
        self.trake_solver: Optional[TRAKESolver] = None
        self.ai_enabled = False # M·∫∑c ƒë·ªãnh l√† False

        if gemini_api_key:
            try:
                genai.configure(api_key=gemini_api_key)
                self.gemini_model = genai.GenerativeModel('gemini-1.5-flash')
                
                # --- TH√äM B∆Ø·ªöC KI·ªÇM TRA API HEALTH ---
                if self._check_api_health():
                    # Ch·ªâ kh·ªüi t·∫°o c√°c handler con n·∫øu API ho·∫°t ƒë·ªông
                    self.semantic_searcher.gemini_model = self.gemini_model
                    self.vqa_handler = VQAHandler(model=self.gemini_model)
                    self.trake_solver = TRAKESolver(gemini_model=self.gemini_model)
                    self.ai_enabled = True
                    print("--- ‚úÖ Gemini v√† c√°c AI Handler ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o v√† x√°c th·ª±c th√†nh c√¥ng! ---")
                else:
                    # N·∫øu health check th·∫•t b·∫°i, v√¥ hi·ªáu h√≥a c√°c t√≠nh nƒÉng AI
                    print("--- ‚ùå Ki·ªÉm tra API th·∫•t b·∫°i. C√°c t√≠nh nƒÉng AI s·∫Ω b·ªã v√¥ hi·ªáu h√≥a. ---")
                    self.ai_enabled = False # ƒê·∫£m b·∫£o v·∫´n l√† False
            except Exception as e:
                print(f"--- ‚ö†Ô∏è L·ªói khi kh·ªüi t·∫°o Gemini: {e}. AI Handler s·∫Ω b·ªã v√¥ hi·ªáu h√≥a. ---")
                self.ai_enabled = False
        else:
            print("--- ‚ö†Ô∏è Kh√¥ng c√≥ API Key. AI Handler (Q&A, TRAKE) s·∫Ω b·ªã v√¥ hi·ªáu h√≥a. ---")
            self.ai_enabled = False
            
        print(f"--- ‚úÖ Master Searcher ƒë√£ s·∫µn s√†ng! (AI Enabled: {self.ai_enabled}) ---")

    # --- H√ÄM M·ªöI ---
    @gemini_api_retrier(max_retries=2, initial_delay=1) # Th·ª≠ l·∫°i 2 l·∫ßn n·∫øu c√≥ l·ªói m·∫°ng t·∫°m th·ªùi
    def _check_api_health(self) -> bool:
        """
        Th·ª±c hi·ªán m·ªôt l·ªánh g·ªçi API ƒë∆°n gi·∫£n ƒë·ªÉ ki·ªÉm tra xem API key c√≥ h·ª£p l·ªá v√† ho·∫°t ƒë·ªông kh√¥ng.
        
        S·ª≠ d·ª•ng count_tokens, m·ªôt API call nh·∫π v√† r·∫ª.

        Returns:
            bool: True n·∫øu API ho·∫°t ƒë·ªông, False n·∫øu kh√¥ng.
        """
        print("--- ü©∫ ƒêang th·ª±c hi·ªán ki·ªÉm tra tr·∫°ng th√°i API Gemini... ---")
        try:
            # count_tokens l√† m·ªôt l·ªánh g·ªçi API nh·∫π nh√†ng nh·∫•t
            self.gemini_model.count_tokens("ki·ªÉm tra")
            print("--- ‚úÖ Tr·∫°ng th√°i API: OK ---")
            return True
        except google_exceptions.PermissionDenied as e:
            # L·ªói n√†y ƒë·∫∑c tr∆∞ng cho API key sai ho·∫∑c kh√¥ng c√≥ quy·ªÅn truy c·∫≠p model
            print(f"--- ‚ùå L·ªói API: Permission Denied. API Key c√≥ th·ªÉ kh√¥ng h·ª£p l·ªá. L·ªói: {e} ---")
            return False
        except Exception as e:
            # B·∫Øt c√°c l·ªói kh√°c (m·∫°ng, etc.)
            print(f"--- ‚ùå L·ªói API: Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn Gemini. L·ªói: {e} ---")
            return False


    def search(self, query: str, top_k: int = 100) -> Dict[str, Any]:
        """
        H√†m t√¨m ki·∫øm ch√≠nh, ƒëi·ªÅu ph·ªëi pipeline theo quy ch·∫ø thi M·ªöI.
        *** PHI√äN B·∫¢N ƒê√É C·∫¨P NH·∫¨T LOGIC T√çNH ƒêI·ªÇM VQA ***
        """
        query_analysis = {}
        
        if self.ai_enabled:
            print("--- üß† B·∫Øt ƒë·∫ßu ph√¢n t√≠ch v√† tƒÉng c∆∞·ªùng truy v·∫•n b·∫±ng Gemini... ---")
            query_analysis = self.semantic_searcher.enhance_query_with_gemini(query)
            task_type = analyze_query_gemini(query, self.gemini_model)
        else:
            print("--- Ch·∫°y ·ªü ch·∫ø ƒë·ªô KIS c∆° b·∫£n do AI b·ªã v√¥ hi·ªáu h√≥a ---")
            query_analysis = {'search_context': query, 'objects_en': query.split()}
            task_type = analyze_query_heuristic(query)
        
        print(f"--- ƒê√£ ph√¢n lo·∫°i truy v·∫•n l√†: {task_type.value} ---")

        final_results = []
        
        if task_type == TaskType.TRAKE:
            if self.trake_solver:
                sub_queries = self.trake_solver.decompose_query(query)
                final_results = self.trake_solver.find_sequences(sub_queries, self.semantic_searcher, max_sequences=top_k)
            else:
                print("--- ‚ö†Ô∏è Kh√¥ng th·ªÉ x·ª≠ l√Ω TRAKE. Fallback v·ªÅ t√¨m ki·∫øm KIS. ---")
                task_type = TaskType.KIS
        
        if task_type == TaskType.KIS or task_type == TaskType.QNA:
            search_context = query_analysis.get('search_context', query)
            
            candidates = self.semantic_searcher.search(
                query_text=search_context, 
                top_k_final=top_k if task_type == TaskType.KIS else 20,
                top_k_retrieval=200,
                precomputed_analysis=query_analysis
            )
            
            if task_type == TaskType.KIS:
                final_results = candidates
            else: # task_type == TaskType.QNA
                if not self.vqa_handler:
                    print("--- ‚ö†Ô∏è Kh√¥ng th·ªÉ x·ª≠ l√Ω QNA. Tr·∫£ v·ªÅ k·∫øt qu·∫£ t√¨m ki·∫øm b·ªëi c·∫£nh. ---")
                    final_results = candidates
                else:
                    specific_question = query_analysis.get('specific_question', query)
                    vqa_enhanced_candidates = []
                    for cand in candidates:
                        vqa_result = self.vqa_handler.get_answer(cand['keyframe_path'], specific_question)
                        
                        new_cand = cand.copy()
                        new_cand['answer'] = vqa_result['answer']
                        
                        # --- LOGIC T√çNH ƒêI·ªÇM M·ªöI ---
                        search_score = new_cand['final_score']
                        vqa_confidence = vqa_result['confidence']
                        final_vqa_score = search_score * vqa_confidence
                        
                        new_cand['final_score'] = final_vqa_score
                        new_cand['scores']['search_score'] = search_score
                        new_cand['scores']['vqa_confidence'] = vqa_confidence
                        
                        vqa_enhanced_candidates.append(new_cand)
                    
                    final_results = sorted(vqa_enhanced_candidates, key=lambda x: x['final_score'], reverse=True)

        return {
            "task_type": task_type,
            "results": final_results[:top_k],
            "query_analysis": query_analysis
        }