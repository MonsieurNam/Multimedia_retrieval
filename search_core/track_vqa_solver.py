from typing import List, Dict, Any

# Import c√°c th√†nh ph·∫ßn c·∫ßn thi·∫øt ƒë·ªÉ type hinting
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from search_core.openai_handler import OpenAIHandler
    from search_core.semantic_searcher import SemanticSearcher
    from search_core.gemini_text_handler import GeminiTextHandler

import time

class TrackVQASolver:
    """
    Class x·ª≠ l√Ω t√°c v·ª• "Theo d√µi v√† T·ªïng h·ª£p Th√¥ng tin" (Track-VQA).

    ƒê√¢y l√† m·ªôt pipeline ph·ª©c t·∫°p bao g·ªìm c√°c b∆∞·ªõc:
    1.  Truy xu·∫•t h√†ng lo·∫°t c√°c kho·∫£nh kh·∫Øc ·ª©ng vi√™n d·ª±a tr√™n b·ªëi c·∫£nh.
    2.  (T∆∞∆°ng lai) L·ªçc v√† gom c·ª•m ƒë·ªÉ t√¨m c√°c kho·∫£nh kh·∫Øc ƒë·ªôc nh·∫•t.
    3.  Th·ª±c hi·ªán VQA tr√™n t·ª´ng kho·∫£nh kh·∫Øc ƒë·ªÉ thu th·∫≠p "b·∫±ng ch·ª©ng".
    4.  S·ª≠ d·ª•ng AI ƒë·ªÉ t·ªïng h·ª£p t·∫•t c·∫£ b·∫±ng ch·ª©ng th√†nh m·ªôt c√¢u tr·∫£ l·ªùi cu·ªëi c√πng.
    """

    def __init__(self, 
                 text_handler: 'GeminiTextHandler', 
                 vision_handler: 'OpenAIHandler', 
                 semantic_searcher: 'SemanticSearcher'):
        """
        Kh·ªüi t·∫°o TrackVQASolver.

        Args:
            text_handler (GeminiTextHandler): Handler ƒë·ªÉ th·ª±c hi·ªán c√°c t√°c v·ª• text (ph√¢n t√≠ch).
            vision_handler (OpenAIHandler): Handler ƒë·ªÉ th·ª±c hi·ªán c√°c t√°c v·ª• vision (VQA l·∫∑p l·∫°i).
            semantic_searcher (SemanticSearcher): Searcher ƒë·ªÉ truy xu·∫•t c√°c kho·∫£nh kh·∫Øc.
        """
        # ƒê·ªïi t√™n self.ai_handler th√†nh c√°c t√™n c·ª• th·ªÉ h∆°n
        self.text_handler = text_handler
        self.vision_handler = vision_handler
        self.searcher = semantic_searcher


    def solve(self, query_analysis: Dict[str, Any], candidates_to_retrieve: int, candidates_to_analyze: int) -> Dict[str, Any]:
        """
        Th·ª±c thi to√†n b·ªô pipeline Track-VQA.
        """
        print("--- üî¨ B·∫Øt ƒë·∫ßu pipeline Track-VQA ---")
        
        # --- 1. Truy xu·∫•t c√°c kho·∫£nh kh·∫Øc ·ª©ng vi√™n ---
        search_context = query_analysis.get('search_context')
        if not search_context:
            return {"final_answer": "L·ªói: Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c b·ªëi c·∫£nh t√¨m ki·∫øm.", "evidence_frames": []}

        print(f"   -> 1/4: ƒêang truy xu·∫•t {candidates_to_retrieve} kho·∫£nh kh·∫Øc cho context: '{search_context}'")
        
        # S·ª≠ d·ª•ng c√°c tham s·ªë t·ª´ config
        candidates = self.searcher.search(
            query_text=search_context, 
            precomputed_analysis=query_analysis,
            top_k_final=candidates_to_retrieve, # L·∫•y s·ªë l∆∞·ª£ng l·ªõn ban ƒë·∫ßu
            top_k_retrieval=candidates_to_retrieve # C√≥ th·ªÉ ƒë·∫∑t b·∫±ng nhau ho·∫∑c tinh ch·ªânh th√™m
        )
        if not candidates:
             return {"final_answer": "Kh√¥ng t√¨m th·∫•y kho·∫£nh kh·∫Øc n√†o ph√π h·ª£p.", "evidence_frames": []}

        # --- 2. L·ªçc v√† Gom c·ª•m ---
        # L·∫•y s·ªë l∆∞·ª£ng ·ª©ng vi√™n ƒë·ªÉ ph√¢n t√≠ch t·ª´ config
        moments_to_analyze = candidates[:candidates_to_analyze]
        print(f"   -> 2/4: ƒê√£ ch·ªçn ra {len(moments_to_analyze)} kho·∫£nh kh·∫Øc h√†ng ƒë·∫ßu ƒë·ªÉ th·ª±c hi·ªán VQA.")

        # --- 3. Th·ª±c hi·ªán VQA l·∫∑p l·∫°i tr√™n t·ª´ng kho·∫£nh kh·∫Øc ---
        specific_question = query_analysis.get('specific_question')
        if not specific_question:
            return {"final_answer": "L·ªói: Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c c√¢u h·ªèi c·ª• th·ªÉ ƒë·ªÉ ph√¢n t√≠ch.", "evidence_frames": []}
            
        print(f"   -> 3/4: ƒêang th·ª±c hi·ªán VQA l·∫∑p l·∫°i v·ªõi c√¢u h·ªèi: '{specific_question}'")
        successful_observations = [] 
        for moment in moments_to_analyze:
            # Ch√∫ng ta c√≥ th·ªÉ th√™m m·ªôt kho·∫£ng ch·ªù nh·ªè ·ªü ƒë√¢y ƒë·ªÉ tr√°nh rate limit
            time.sleep(0.5) 
            vqa_result = self.vision_handler.perform_vqa(moment['keyframe_path'], specific_question)
            print(f"     -> Ph·∫£n h·ªìi API: {vqa_result}")

            # L·ªçc c√¢u tr·∫£ l·ªùi d·ª±a tr√™n ƒë·ªô t·ª± tin
            if vqa_result and vqa_result.get('confidence', 0) > 0.6:
                answer_text = vqa_result.get('answer', '')
                successful_observations.append({
                    "answer": vqa_result.get('answer', ''),
                    "frame_info": moment 
                })
                print(f"     -> ‚úÖ K·∫øt qu·∫£ ƒë∆∞·ª£c ch·∫•p nh·∫≠n (Conf > 0.6): '{answer_text}'")
            else:
                print(f"     -> ‚ùå K·∫øt qu·∫£ b·ªã lo·∫°i b·ªè (Conf <= 0.6 ho·∫∑c l·ªói).")

        if not successful_observations:
            return {"final_answer": "Kh√¥ng th·ªÉ thu th·∫≠p ƒë·ªß th√¥ng tin t·ª´ c√°c kho·∫£nh kh·∫Øc.", "evidence_frames": []}
        # T√°ch ri√™ng danh s√°ch c√¢u tr·∫£ l·ªùi ƒë·ªÉ t·ªïng h·ª£p
        instance_answers = [obs['answer'] for obs in successful_observations]
        
        # --- 4. T·ªïng h·ª£p c√°c c√¢u tr·∫£ l·ªùi th√†nh m·ªôt k·∫øt qu·∫£ duy nh·∫•t ---
        aggregation_instruction = query_analysis.get('aggregation_instruction')
        if not aggregation_instruction:
            return {"final_answer": "L·ªói: Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c c√°ch t·ªïng h·ª£p k·∫øt qu·∫£.", "evidence_frames": []}

        print(f"   -> 4/4: ƒêang t·ªïng h·ª£p {len(instance_answers)} c√¢u tr·∫£ l·ªùi...")
        final_answer = self.aggregate_answers(instance_answers, aggregation_instruction)
        
        evidence_frames = [obs['frame_info'] for obs in successful_observations]
        
        print(f"--- ‚úÖ Pipeline Track-VQA ho√†n t·∫•t! ---")
        
        return {
            "final_answer": final_answer,
            "evidence_frames": evidence_frames # Tr·∫£ v·ªÅ c√°c frame ƒë√£ th·ª±c s·ª± ƒë√≥ng g√≥p v√†o c√¢u tr·∫£ l·ªùi
        }

    def aggregate_answers(self, answers: List[str], instruction: str) -> str:
        """
        S·ª≠ d·ª•ng AI ƒë·ªÉ t·ªïng h·ª£p m·ªôt danh s√°ch c√°c c√¢u tr·∫£ l·ªùi ri√™ng l·∫ª.
        ƒê√¢y l√† b∆∞·ªõc suy lu·∫≠n cu·ªëi c√πng.

        Args:
            answers (List[str]): Danh s√°ch c√°c c√¢u tr·∫£ l·ªùi t·ª´ VQA tr√™n t·ª´ng frame.
            instruction (str): H∆∞·ªõng d·∫´n c√°ch t·ªïng h·ª£p (v√≠ d·ª•: "ƒë·∫øm v√† li·ªát k√™ m√†u").

        Returns:
            str: C√¢u tr·∫£ l·ªùi t·ªïng h·ª£p cu·ªëi c√πng.
        """
        # Chuy·ªÉn danh s√°ch th√†nh m·ªôt chu·ªói d·ªÖ ƒë·ªçc cho AI
        formatted_answers = "\n".join([f"- {ans}" for ans in answers])
        
        prompt = f"""
        You are a data synthesis AI. Your task is to analyze a list of individual observations from different video frames and synthesize them into a single, final answer based on the user's ultimate goal. Be concise and directly answer the user's original intent.

        **Individual Observations:**
        {formatted_answers}

        **User's Final Goal:**
        "{instruction}"

        **Synthesized Final Answer (in Vietnamese):**
        """
        
        try:
            response = self.text_handler._gemini_text_call(prompt)
            return response.text
        except Exception as e:
            print(f"--- ‚ö†Ô∏è L·ªói khi t·ªïng h·ª£p c√¢u tr·∫£ l·ªùi: {e} ---")
            return "Kh√¥ng th·ªÉ t·ªïng h·ª£p. C√°c quan s√°t ri√™ng l·∫ª: " + ", ".join(answers)