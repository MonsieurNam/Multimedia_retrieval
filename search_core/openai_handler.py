# /kaggle/working/search_core/openai_handler.py

import openai
import json
import re
import base64
from typing import Dict, Any, List, Optional

from utils import api_retrier

class OpenAIHandler:
    """
    M·ªôt class "adapter" ƒë·ªÉ ƒë√≥ng g√≥i t·∫•t c·∫£ c√°c l·ªánh g·ªçi API ƒë·∫øn OpenAI.
    Che gi·∫•u s·ª± ph·ª©c t·∫°p c·ªßa vi·ªác g·ªçi API v√† cung c·∫•p c√°c ph∆∞∆°ng th·ª©c
    r√µ r√†ng cho c√°c t√°c v·ª• c·ª• th·ªÉ (ph√¢n t√≠ch, VQA, etc.).
    """
    def __init__(self, api_key: str, model: str = "gpt-4o-mini"):
        """
        Kh·ªüi t·∫°o OpenAI Handler.

        Args:
            api_key (str): OpenAI API key.
            model (str): T√™n model m·∫∑c ƒë·ªãnh cho c√°c t√°c v·ª• text.
                         GPT-4o-mini l√† m·ªôt l·ª±a ch·ªçn t·ªët v·ªÅ t·ªëc ƒë·ªô v√† chi ph√≠.
        """
        print(f"--- ü§ñ Kh·ªüi t·∫°o OpenAI Handler v·ªõi model m·∫∑c ƒë·ªãnh: {model} ---")
        self.client = openai.OpenAI(api_key=api_key)
        self.model = model
        # GPT-4o l√† model vision m·∫°nh m·∫Ω nh·∫•t hi·ªán t·∫°i c·ªßa OpenAI
        self.vision_model = "gpt-4o"

    @api_retrier(max_retries=3, initial_delay=2)
    def _openai_chat_completion(self, messages: List[Dict], is_json: bool = True, is_vision: bool = False) -> Optional[str]: # Th√™m Optional[str]
        """
        H√†m con chung ƒë·ªÉ th·ª±c hi·ªán c√°c l·ªánh g·ªçi API chat completion.
        *** PHI√äN B·∫¢N AN TO√ÄN H∆†N ***
        """
        model_to_use = self.vision_model if is_vision else self.model
        response_format = {"type": "json_object"} if is_json else {"type": "text"}
        
        response = self.client.chat.completions.create(
            model=model_to_use,
            messages=messages,
            response_format=response_format,
            temperature=0.1,
            max_tokens=1024
        )
        
        # --- TH√äM KI·ªÇM TRA T·∫†I ƒê√ÇY ---
        if response.choices and response.choices[0].message:
            content = response.choices[0].message.content
            # Tr·∫£ v·ªÅ chu·ªói r·ªóng n·∫øu content l√† None, thay v√¨ tr·∫£ v·ªÅ ch√≠nh None
            return content if content is not None else "" 
        
        # N·∫øu kh√¥ng c√≥ choices ho·∫∑c message, tr·∫£ v·ªÅ chu·ªói r·ªóng
        return ""

    def _encode_image_to_base64(self, image_path: str) -> str:
        """M√£ h√≥a m·ªôt file ·∫£nh th√†nh chu·ªói base64."""
        try:
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
        except Exception as e:
            print(f"--- ‚ö†Ô∏è L·ªói khi m√£ h√≥a ·∫£nh {image_path}: {e} ---")
            return ""

    def enhance_query(self, query: str) -> Dict[str, Any]:
        """
        Ph√¢n t√≠ch, tƒÉng c∆∞·ªùng v√† d·ªãch truy v·∫•n c·ªßa ng∆∞·ªùi d√πng.
        """
        fallback_result = {'search_context': query, 'specific_question': "", 'objects_vi': [], 'objects_en': []}
        prompt = f"""
        Analyze a Vietnamese user query for a video search system. Return ONLY a valid JSON object with: "search_context", "specific_question", "objects_vi", and "objects_en".

        Rules:
        - "search_context": A Vietnamese phrase for finding the scene.
        - "specific_question": The specific question. For KIS queries, this is an empty string "".
        - "objects_vi": A list of Vietnamese nouns/entities.
        - "objects_en": The English translation for EACH item in "objects_vi". The two lists must have the same length.

        Example (VQA):
        Query: "Trong video quay c·∫£nh b·ªØa ti·ªác, ng∆∞·ªùi ph·ª• n·ªØ m·∫∑c v√°y ƒë·ªè ƒëang c·∫ßm ly m√†u g√¨?"
        JSON: {{"search_context": "c·∫£nh b·ªØa ti·ªác c√≥ ng∆∞·ªùi ph·ª• n·ªØ m·∫∑c v√°y ƒë·ªè", "specific_question": "c√¥ ·∫•y ƒëang c·∫ßm ly m√†u g√¨?", "objects_vi": ["b·ªØa ti·ªác", "ng∆∞·ªùi ph·ª• n·ªØ", "v√°y ƒë·ªè"], "objects_en": ["party", "woman", "red dress"]}}

        Query: "{query}"
        JSON:
        """
        try:
            response_content = self._openai_chat_completion([{"role": "user", "content": prompt}], is_json=True)
            result = json.loads(response_content)
            # Validate...
            if all(k in result for k in ['search_context', 'specific_question', 'objects_vi', 'objects_en']):
                return result
            return fallback_result
        except Exception as e:
            print(f"L·ªói OpenAI enhance_query: {e}")
            return fallback_result

    def analyze_task_type(self, query: str) -> str:
        """
        Ph√¢n lo·∫°i truy v·∫•n th√†nh 'KIS', 'QNA', ho·∫∑c 'TRAKE' v·ªõi ƒë·ªô ch√≠nh x√°c cao h∆°n.
        S·ª≠ d·ª•ng prompt ƒë∆∞·ª£c tinh ch·ªânh v·ªõi ƒë·ªãnh nghƒ©a r√µ r√†ng v√† v√≠ d·ª• 'b·∫´y'.
        """
        # Prompt m·ªõi, chi ti·∫øt h∆°n r·∫•t nhi·ªÅu
        prompt = f"""
        You are an expert query classifier. Your task is to analyze a Vietnamese user query and classify it into one of three strict categories: "KIS", "QNA", or "TRAKE".

        **Category Definitions:**
        1.  **QNA (Question Answering):** The query MUST be a direct question. It typically starts with interrogative words (Ai, C√°i g√¨, ·ªû ƒë√¢u, Khi n√†o, Nh∆∞ th·∫ø n√†o, T·∫°i sao, Bao nhi√™u) or ends with a question mark (?). The user is asking for a specific piece of information that is NOT the video itself.
        2.  **TRAKE (Temporal Alignment):** The query explicitly asks for a SEQUENCE of multiple, ordered events. It often contains numbers, steps (b∆∞·ªõc 1, b∆∞·ªõc 2), or a list of actions separated by commas or "and".
        3.  **KIS (Knowledge Intensive Search):** This is the default category. The query is a descriptive statement or phrase. It describes a scene, an object, or an action the user wants to find. **If the query is NOT a direct question and NOT a sequence, it is KIS.**

        **Chain of Thought Analysis:**
        - First, check if the query is a direct question. Does it ask "what", "who", "where", "how many"? If yes, it is **QNA**.
        - If not a question, check if it asks for a sequence of multiple steps. Does it say "(1)...(2)..." or "first this, then that"? If yes, it is **TRAKE**.
        - If it's neither a question nor a sequence, it is a description of a scene. Therefore, it is **KIS**.

        **Examples:**
        - Query: "c√°i g√¨ m√†u xanh tr√™n b√†n?" -> QNA (Direct question)
        - Query: "t√¨m c·∫£nh ng∆∞·ªùi ƒë√†n √¥ng (1) ƒë·ª©ng l√™n v√† (2) r·ªùi ƒëi" -> TRAKE (Sequence)
        - Query: "ng∆∞·ªùi ƒë√†n √¥ng ph√°t bi·ªÉu ·ªü m·ªπ" -> KIS (This is a DESCRIPTION of a scene, not a question asking where he is)
        - Query: "m·ªôt ng∆∞·ªùi ph·ª• n·ªØ m·∫∑c √°o d√†i" -> KIS (A description)
        - Query: "C√≥ bao nhi√™u chi·∫øc xe tr√™n ƒë∆∞·ªùng?" -> QNA (Direct question)

        **Your Task:**
        Analyze the following query and return ONLY the category as a single word: KIS, QNA, or TRAKE.

        Query: "{query}"
        Category:
        """
        try:
            response = self._openai_chat_completion([{"role": "user", "content": prompt}], is_json=False)
            task_type = response.strip().upper()
            if task_type in ["KIS", "QNA", "TRAKE"]:
                print(f"--- ‚úÖ Ph√¢n lo·∫°i truy v·∫•n (OpenAI): '{query}' -> {task_type} ---")
                return task_type
            # N·∫øu AI tr·∫£ v·ªÅ m·ªôt k·∫øt qu·∫£ l·∫°, fallback v·ªÅ heuristic
            print(f"--- ‚ö†Ô∏è Ph√¢n lo·∫°i kh√¥ng h·ª£p l·ªá t·ª´ OpenAI: '{task_type}'. Fallback v·ªÅ Heuristic. ---")
            return self._analyze_query_heuristic_fallback(query)

        except Exception as e:
            print(f"L·ªói OpenAI analyze_task_type: {e}. Fallback v·ªÅ Heuristic.")
            return self._analyze_query_heuristic_fallback(query)

    def _analyze_query_heuristic_fallback(self, query: str) -> str:
        """
        H√†m heuristic d·ª± ph√≤ng, ƒë∆∞·ª£c gi·ªØ l·∫°i ƒë·ªÉ ƒë·∫£m b·∫£o h·ªá th·ªëng lu√¥n ho·∫°t ƒë·ªông.
        """
        query_lower = query.lower().strip()
        qna_keywords = ['m√†u g√¨', 'ai l√†', 'ai ƒëang', '·ªü ƒë√¢u', 'khi n√†o', 't·∫°i sao', 'c√°i g√¨', 'bao nhi√™u']
        if '?' in query or any(query_lower.startswith(k) for k in qna_keywords):
            return "QNA"
        trake_pattern = r'\(\d+\)|b∆∞·ªõc \d+|\d\.'
        if re.search(trake_pattern, query_lower) or "t√¨m c√°c kho·∫£nh kh·∫Øc" in query_lower:
            return "TRAKE"
        return "KIS"

    def perform_vqa(self, image_path: str, question: str) -> Dict[str, any]:
        """
        Th·ª±c hi·ªán VQA s·ª≠ d·ª•ng GPT-4o.
        *** PHI√äN B·∫¢N C√ì X·ª¨ L√ù L·ªñI T·ªêT H∆†N ***
        """
        base64_image = self._encode_image_to_base64(image_path)
        if not base64_image:
            return {"answer": "L·ªói: Kh√¥ng th·ªÉ x·ª≠ l√Ω ·∫£nh", "confidence": 0.0}

        prompt = f"""...""" # Prompt VQA gi·ªØ nguy√™n
        
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"},
                    },
                ],
            }
        ]
        try:
            response_content = self._openai_chat_completion(messages, is_json=True, is_vision=True)
            
            # --- TH√äM KI·ªÇM TRA T·∫†I ƒê√ÇY ---
            # N·∫øu _openai_chat_completion tr·∫£ v·ªÅ chu·ªói r·ªóng do l·ªói ho·∫∑c API kh√¥ng tr·∫£ l·ªùi
            if not response_content:
                print("--- ‚ö†Ô∏è OpenAI VQA kh√¥ng tr·∫£ v·ªÅ n·ªôi dung. ---")
                return {"answer": "Kh√¥ng th·ªÉ ph√¢n t√≠ch h√¨nh ·∫£nh", "confidence": 0.1}

            result = json.loads(response_content)
            return {
                "answer": result.get("answer", "Kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi"),
                "confidence": float(result.get("confidence", 0.5))
            }
        except (json.JSONDecodeError, TypeError) as e:
             # B·∫Øt c·∫£ l·ªói TypeError t·ª´ json.loads(None) v√† JSONDecodeError
            print(f"L·ªói OpenAI perform_vqa (JSON parsing): {e}. Response nh·∫≠n ƒë∆∞·ª£c: '{response_content}'")
            return {"answer": "L·ªói ƒë·ªãnh d·∫°ng ph·∫£n h·ªìi", "confidence": 0.0}
        except Exception as e:
            print(f"L·ªói kh√¥ng x√°c ƒë·ªãnh trong OpenAI perform_vqa: {e}")
            return {"answer": "L·ªói x·ª≠ l√Ω VQA", "confidence": 0.0}

    def decompose_trake_query(self, query: str) -> List[str]:
        """Ph√¢n r√£ truy v·∫•n TRAKE th√†nh c√°c b∆∞·ªõc con."""
        prompt = f"""
        Decompose the Vietnamese query describing a sequence of actions into a JSON array of short, self-contained phrases. Return ONLY the JSON array.

        Example:
        Query: "T√¨m 4 kho·∫£nh kh·∫Øc ch√≠nh khi v·∫≠n ƒë·ªông vi√™n th·ª±c hi·ªán c√∫ nh·∫£y: (1) gi·∫≠m nh·∫£y, (2) bay qua x√†, (3) ti·∫øp ƒë·∫•t, (4) ƒë·ª©ng d·∫≠y."
        JSON: ["v·∫≠n ƒë·ªông vi√™n gi·∫≠m nh·∫£y", "v·∫≠n ƒë·ªông vi√™n bay qua x√†", "v·∫≠n ƒë·ªông vi√™n ti·∫øp ƒë·∫•t", "v·∫≠n ƒë·ªông vi√™n ƒë·ª©ng d·∫≠y"]

        Query: "{query}"
        JSON:
        """
        try:
            response_content = self._openai_chat_completion([{"role": "user", "content": prompt}], is_json=True)
            result = json.loads(response_content)
            if isinstance(result, list):
                return result
            return [query] # Fallback
        except Exception as e:
            print(f"L·ªói OpenAI decompose_trake_query: {e}")
            return [query]