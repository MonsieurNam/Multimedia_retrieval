# /kaggle/working/search_core/openai_handler.py

import openai
import json
import re
import base64
from typing import Dict, Any, List, Optional

from utils import api_retrier

class OpenAIHandler:
    """
    M·ªôt class "adapter" ƒë·ªÉ ƒë√≥ng g√≥i t·∫•t c·∫£ c√°c l·ªánh g·ªçi API ƒë·∫øn OpenAI.
    Che gi·∫•u s·ª± ph·ª©c t·∫°p c·ªßa vi·ªác g·ªçi API v√† cung c·∫•p c√°c ph∆∞∆°ng th·ª©c
    r√µ r√†ng cho c√°c t√°c v·ª• c·ª• th·ªÉ (ph√¢n t√≠ch, VQA, etc.).
    """
    def __init__(self, api_key: str, model: str = "gpt-4o-mini"):
        """
        Kh·ªüi t·∫°o OpenAI Handler.

        Args:
            api_key (str): OpenAI API key.
            model (str): T√™n model m·∫∑c ƒë·ªãnh cho c√°c t√°c v·ª• text.
                         GPT-4o-mini l√† m·ªôt l·ª±a ch·ªçn t·ªët v·ªÅ t·ªëc ƒë·ªô v√† chi ph√≠.
        """
        print(f"--- ü§ñ Kh·ªüi t·∫°o OpenAI Handler v·ªõi model m·∫∑c ƒë·ªãnh: {model} ---")
        self.client = openai.OpenAI(api_key=api_key)
        self.model = model
        # GPT-4o l√† model vision m·∫°nh m·∫Ω nh·∫•t hi·ªán t·∫°i c·ªßa OpenAI
        self.vision_model = "gpt-4o"
        
    @api_retrier(max_retries=2, initial_delay=1)
    def check_api_health(self) -> bool:
        """
        Th·ª±c hi·ªán m·ªôt l·ªánh g·ªçi API ƒë∆°n gi·∫£n ƒë·ªÉ ki·ªÉm tra xem API key c√≥ h·ª£p l·ªá v√† ho·∫°t ƒë·ªông kh√¥ng.
        
        S·ª≠ d·ª•ng vi·ªác t·∫°o embedding cho m·ªôt t·ª´ ng·∫Øn, ƒë√¢y l√† m·ªôt API call nh·∫π v√† r·∫ª.

        Returns:
            bool: True n·∫øu API ho·∫°t ƒë·ªông, False n·∫øu kh√¥ng.
        """
        print("--- ü©∫ ƒêang th·ª±c hi·ªán ki·ªÉm tra tr·∫°ng th√°i API OpenAI... ---")
        try:
            # text-embedding-ada-002 ho·∫∑c text-embedding-3-small l√† l·ª±a ch·ªçn t·ªët
            self.client.embeddings.create(
                input="ki·ªÉm tra",
                model="text-embedding-3-small"
            )
            print("--- ‚úÖ Tr·∫°ng th√°i API OpenAI: OK ---")
            return True
        except openai.AuthenticationError as e:
            # L·ªói n√†y ƒë·∫∑c tr∆∞ng cho API key sai ho·∫∑c kh√¥ng h·ª£p l·ªá
            print(f"--- ‚ùå L·ªói OpenAI API: Authentication Error. API Key c√≥ th·ªÉ kh√¥ng h·ª£p l·ªá. L·ªói: {e} ---")
            return False
        except Exception as e:
            # B·∫Øt c√°c l·ªói kh√°c (m·∫°ng, etc.)
            print(f"--- ‚ùå L·ªói OpenAI API: Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn OpenAI. L·ªói: {e} ---")
            return False

    @api_retrier(max_retries=3, initial_delay=2)
    def _openai_vision_call(self, messages: List[Dict], is_json: bool = True, is_vision: bool = False) -> Optional[str]: # Th√™m Optional[str]
        """
        H√†m con chung ƒë·ªÉ th·ª±c hi·ªán c√°c l·ªánh g·ªçi API chat completion.
        *** PHI√äN B·∫¢N AN TO√ÄN H∆†N ***
        """
        model_to_use = self.vision_model if is_vision else self.model
        response_format = {"type": "json_object"} if is_json else {"type": "text"}
        
        response = self.client.chat.completions.create(
            model=model_to_use,
            messages=messages,
            response_format=response_format,
            temperature=0.1,
            max_tokens=1024
        )
        
        # --- TH√äM KI·ªÇM TRA T·∫†I ƒê√ÇY ---
        if response.choices and response.choices[0].message:
            content = response.choices[0].message.content
            # Tr·∫£ v·ªÅ chu·ªói r·ªóng n·∫øu content l√† None, thay v√¨ tr·∫£ v·ªÅ ch√≠nh None
            return content if content is not None else "" 
        
        # N·∫øu kh√¥ng c√≥ choices ho·∫∑c message, tr·∫£ v·ªÅ chu·ªói r·ªóng
        return ""

    def _encode_image_to_base64(self, image_path: str) -> str:
        """M√£ h√≥a m·ªôt file ·∫£nh th√†nh chu·ªói base64."""
        try:
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
        except Exception as e:
            print(f"--- ‚ö†Ô∏è L·ªói khi m√£ h√≥a ·∫£nh {image_path}: {e} ---")
            return ""

    def enhance_query(self, query: str) -> Dict[str, Any]:
        """
        Ph√¢n t√≠ch, tƒÉng c∆∞·ªùng v√† d·ªãch truy v·∫•n c·ªßa ng∆∞·ªùi d√πng.
        """
        fallback_result = {'search_context': query, 'specific_question': "", 'objects_vi': [], 'objects_en': []}
        prompt = f"""
        Analyze a Vietnamese user query for a video search system. **Return ONLY a valid JSON object** with: "search_context", "specific_question", "objects_vi", and "objects_en".

        Rules:
        - "search_context": A Vietnamese phrase for finding the scene.
        - "specific_question": The specific question. For KIS queries, this is an empty string "".
        - "objects_vi": A list of Vietnamese nouns/entities.
        - "objects_en": The English translation for EACH item in "objects_vi". The two lists must have the same length.

        Example (VQA):
        Query: "Trong video quay c·∫£nh b·ªØa ti·ªác, ng∆∞·ªùi ph·ª• n·ªØ m·∫∑c v√°y ƒë·ªè ƒëang c·∫ßm ly m√†u g√¨?"
        JSON: {{"search_context": "c·∫£nh b·ªØa ti·ªác c√≥ ng∆∞·ªùi ph·ª• n·ªØ m·∫∑c v√°y ƒë·ªè", "specific_question": "c√¥ ·∫•y ƒëang c·∫ßm ly m√†u g√¨?", "objects_vi": ["b·ªØa ti·ªác", "ng∆∞·ªùi ph·ª• n·ªØ", "v√°y ƒë·ªè"], "objects_en": ["party", "woman", "red dress"]}}

        Query: "{query}"
        JSON:
        """
        try:
            response_content = self._openai_chat_completion([{"role": "user", "content": prompt}], is_json=True)
            result = json.loads(response_content)
            # Validate...
            if all(k in result for k in ['search_context', 'specific_question', 'objects_vi', 'objects_en']):
                return result
            return fallback_result
        except Exception as e:
            print(f"L·ªói OpenAI enhance_query: {e}")
            return fallback_result

    def analyze_task_type(self, query: str) -> str:
        """
        Ph√¢n lo·∫°i truy v·∫•n v·ªõi Quy t·∫Øc ∆Øu ti√™n ƒë·ªÉ x·ª≠ l√Ω c√°c tr∆∞·ªùng h·ª£p lai.
        """
        prompt = f"""
        You are a highly precise query classifier. Your task is to classify a Vietnamese query into one of four categories: TRACK_VQA, TRAKE, QNA, or KIS. You MUST follow a strict priority order.

        **Priority Order for Classification (Check from top to bottom):**

        1.  **Check for TRACK_VQA first:** Does the query ask a question about a COLLECTION of items, requiring aggregation (counting, listing, summarizing)? Look for keywords like "ƒë·∫øm", "bao nhi√™u", "li·ªát k√™", "t·∫•t c·∫£", "m·ªói", or plural subjects. If it matches, classify as **TRACK_VQA** and stop.
            - Example: "trong bu·ªïi tr√¨nh di·ªÖn m√∫a l√¢n, ƒë·∫øm xem c√≥ bao nhi√™u con l√¢n" -> This is a request to count a collection, so it is **TRACK_VQA**.

        2.  **Then, check for TRAKE:** If it's not TRACK_VQA, does the query ask for a SEQUENCE of DIFFERENT, ordered actions? Look for patterns like "(1)...(2)...", "b∆∞·ªõc 1... b∆∞·ªõc 2", "sau ƒë√≥". If it matches, classify as **TRAKE** and stop.
            - Example: "ng∆∞·ªùi ƒë√†n √¥ng ƒë·ª©ng l√™n r·ªìi b∆∞·ªõc ƒëi"

        3.  **Then, check for QNA:** If it's not TRACK_VQA or TRAKE, is it a direct question about a SINGLE item? Look for a question mark "?" or interrogative words like "c√°i g√¨", "ai". If it matches, classify as **QNA** and stop.
            - Example: "ng∆∞·ªùi ph·ª• n·ªØ m·∫∑c √°o m√†u g√¨?"

        4.  **Default to KIS:** If the query does not meet any of the criteria above, it is a simple description of a scene. Classify as **KIS**.
            - Example: "c·∫£nh m√∫a l√¢n"

        **Your Task:**
        Follow the priority order strictly. Analyze the query below and return ONLY the final category as a single word.

        **Query:** "{query}"
        **Category:**
        """
        try:
            # S·ª≠ d·ª•ng h√†m chat completion ƒë√£ c√≥
            response = self._openai_chat_completion([{"role": "user", "content": prompt}], is_json=False)
            task_type = response.strip().upper()
            
            # Ki·ªÉm tra xem k·∫øt qu·∫£ tr·∫£ v·ªÅ c√≥ h·ª£p l·ªá kh√¥ng
            if task_type in ["KIS", "QNA", "TRAKE", "TRACK_VQA"]:
                print(f"--- ‚úÖ Ph√¢n lo·∫°i truy v·∫•n (OpenAI): '{query}' -> {task_type} ---")
                return task_type
                
            print(f"--- ‚ö†Ô∏è Ph√¢n lo·∫°i kh√¥ng h·ª£p l·ªá t·ª´ OpenAI: '{task_type}'. Fallback v·ªÅ Heuristic. ---")
            return self._analyze_query_heuristic_fallback(query) # V·∫´n gi·ªØ fallback

        except Exception as e:
            print(f"L·ªói OpenAI analyze_task_type: {e}. Fallback v·ªÅ Heuristic.")
            return self._analyze_query_heuristic_fallback(query)

    # C·∫≠p nh·∫≠t h√†m fallback heuristic ƒë·ªÉ n√≥ kh√¥ng bao gi·ªù tr·∫£ v·ªÅ TRACK_VQA
    def _analyze_query_heuristic_fallback(self, query: str) -> str:
        """
        H√†m heuristic d·ª± ph√≤ng. S·∫Ω kh√¥ng ph√¢n lo·∫°i TRACK_VQA, ƒë·ªÉ an to√†n.
        """
        query_lower = query.lower().strip()
        qna_keywords = ['m√†u g√¨', 'ai l√†', 'ai ƒëang', '·ªü ƒë√¢u', 'khi n√†o', 't·∫°i sao', 'c√°i g√¨', 'bao nhi√™u']
        if '?' in query or any(query_lower.startswith(k) for k in qna_keywords):
            # L∆∞u √Ω: "bao nhi√™u" c√≥ th·ªÉ l√† TRACK_VQA, nh∆∞ng trong heuristic ta ∆∞u ti√™n QNA cho an to√†n
            return "QNA"
        trake_pattern = r'\(\d+\)|b∆∞·ªõc \d+|\d\.'
        if re.search(trake_pattern, query_lower) or "t√¨m c√°c kho·∫£nh kh·∫Øc" in query_lower:
            return "TRAKE"
        return "KIS"

    def perform_vqa(self, image_path: str, question: str) -> Dict[str, any]:
        """
        Th·ª±c hi·ªán VQA s·ª≠ d·ª•ng GPT-4o.
        *** PHI√äN B·∫¢N C√ì X·ª¨ L√ù L·ªñI T·ªêT H∆†N ***
        """
        base64_image = self._encode_image_to_base64(image_path)
        if not base64_image:
            return {"answer": "L·ªói: Kh√¥ng th·ªÉ x·ª≠ l√Ω ·∫£nh", "confidence": 0.0}

        prompt = f"""
        You are a Visual Question Answering assistant. Based on the provided image, answer the user's question.
        
        **Your task is to return ONLY a valid JSON object** with two keys: "answer" and "confidence".
        - "answer": A short, direct answer in Vietnamese.
        - "confidence": Your confidence in the answer, from 0.0 (very unsure) to 1.0 (certain).

        **User's Question:** "{question}"
        """
        
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"},
                    },
                ],
            }
        ]
        try:
            response_content = self._openai_chat_completion(messages, is_json=True, is_vision=True)
            
            if not response_content:
                print("--- ‚ö†Ô∏è OpenAI VQA kh√¥ng tr·∫£ v·ªÅ n·ªôi dung. ---")
                return {"answer": "Kh√¥ng th·ªÉ ph√¢n t√≠ch h√¨nh ·∫£nh", "confidence": 0.1}

            result = json.loads(response_content)
            return {
                "answer": result.get("answer", "Kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi"),
                "confidence": float(result.get("confidence", 0.5))
            }
        except (json.JSONDecodeError, TypeError) as e:
             # B·∫Øt c·∫£ l·ªói TypeError t·ª´ json.loads(None) v√† JSONDecodeError
            print(f"L·ªói OpenAI perform_vqa (JSON parsing): {e}. Response nh·∫≠n ƒë∆∞·ª£c: '{response_content}'")
            return {"answer": "L·ªói ƒë·ªãnh d·∫°ng ph·∫£n h·ªìi", "confidence": 0.0}
        except Exception as e:
            print(f"L·ªói kh√¥ng x√°c ƒë·ªãnh trong OpenAI perform_vqa: {e}")
            return {"answer": "L·ªói x·ª≠ l√Ω VQA", "confidence": 0.0}

    def decompose_trake_query(self, query: str) -> List[str]:
        """Ph√¢n r√£ truy v·∫•n TRAKE th√†nh c√°c b∆∞·ªõc con."""
        prompt = f"""
        Decompose the Vietnamese query describing a sequence of actions into a JSON array of short, self-contained phrases. Return ONLY the JSON array.

        Example:
        Query: "T√¨m 4 kho·∫£nh kh·∫Øc ch√≠nh khi v·∫≠n ƒë·ªông vi√™n th·ª±c hi·ªán c√∫ nh·∫£y: (1) gi·∫≠m nh·∫£y, (2) bay qua x√†, (3) ti·∫øp ƒë·∫•t, (4) ƒë·ª©ng d·∫≠y."
        JSON: ["v·∫≠n ƒë·ªông vi√™n gi·∫≠m nh·∫£y", "v·∫≠n ƒë·ªông vi√™n bay qua x√†", "v·∫≠n ƒë·ªông vi√™n ti·∫øp ƒë·∫•t", "v·∫≠n ƒë·ªông vi√™n ƒë·ª©ng d·∫≠y"]

        Query: "{query}"
        JSON:
        """
        try:
            response_content = self._openai_chat_completion([{"role": "user", "content": prompt}], is_json=True)
            result = json.loads(response_content)
            if isinstance(result, list):
                return result
            return [query] # Fallback
        except Exception as e:
            print(f"L·ªói OpenAI decompose_trake_query: {e}")
            return [query]