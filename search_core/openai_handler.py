# /kaggle/working/search_core/openai_handler.py

import openai
import json
import re
import base64
from typing import Dict, Any, List

from utils import api_retrier

class OpenAIHandler:
    """
    Má»™t class "adapter" Ä‘á»ƒ Ä‘Ã³ng gÃ³i táº¥t cáº£ cÃ¡c lá»‡nh gá»i API Ä‘áº¿n OpenAI.
    Che giáº¥u sá»± phá»©c táº¡p cá»§a viá»‡c gá»i API vÃ  cung cáº¥p cÃ¡c phÆ°Æ¡ng thá»©c
    rÃµ rÃ ng cho cÃ¡c tÃ¡c vá»¥ cá»¥ thá»ƒ (phÃ¢n tÃ­ch, VQA, etc.).
    """
    def __init__(self, api_key: str, model: str = "gpt-4o-mini"):
        """
        Khá»Ÿi táº¡o OpenAI Handler.

        Args:
            api_key (str): OpenAI API key.
            model (str): TÃªn model máº·c Ä‘á»‹nh cho cÃ¡c tÃ¡c vá»¥ text.
                         GPT-4o-mini lÃ  má»™t lá»±a chá»n tá»‘t vá» tá»‘c Ä‘á»™ vÃ  chi phÃ­.
        """
        print(f"--- ðŸ¤– Khá»Ÿi táº¡o OpenAI Handler vá»›i model máº·c Ä‘á»‹nh: {model} ---")
        self.client = openai.OpenAI(api_key=api_key)
        self.model = model
        # GPT-4o lÃ  model vision máº¡nh máº½ nháº¥t hiá»‡n táº¡i cá»§a OpenAI
        self.vision_model = "gpt-4o"

    @api_retrier(max_retries=3, initial_delay=2)
    def _openai_chat_completion(self, messages: List[Dict], is_json: bool = True, is_vision: bool = False):
        """
        HÃ m con chung Ä‘á»ƒ thá»±c hiá»‡n cÃ¡c lá»‡nh gá»i API chat completion.

        Args:
            messages (List[Dict]): Danh sÃ¡ch cÃ¡c message theo Ä‘á»‹nh dáº¡ng OpenAI.
            is_json (bool): True náº¿u muá»‘n model tráº£ vá» JSON object.
            is_vision (bool): True náº¿u Ä‘Ã¢y lÃ  má»™t lá»‡nh gá»i cÃ³ hÃ¬nh áº£nh.
        """
        model_to_use = self.vision_model if is_vision else self.model
        response_format = {"type": "json_object"} if is_json else {"type": "text"}
        
        response = self.client.chat.completions.create(
            model=model_to_use,
            messages=messages,
            response_format=response_format,
            temperature=0.1, # Giáº£m nhiá»‡t Ä‘á»™ Ä‘á»ƒ káº¿t quáº£ nháº¥t quÃ¡n
            max_tokens=1024  # Giá»›i háº¡n token Ä‘á»ƒ trÃ¡nh chi phÃ­ khÃ´ng mong muá»‘n
        )
        return response.choices[0].message.content

    def _encode_image_to_base64(self, image_path: str) -> str:
        """MÃ£ hÃ³a má»™t file áº£nh thÃ nh chuá»—i base64."""
        try:
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
        except Exception as e:
            print(f"--- âš ï¸ Lá»—i khi mÃ£ hÃ³a áº£nh {image_path}: {e} ---")
            return ""

    def enhance_query(self, query: str) -> Dict[str, Any]:
        """
        PhÃ¢n tÃ­ch, tÄƒng cÆ°á»ng vÃ  dá»‹ch truy váº¥n cá»§a ngÆ°á»i dÃ¹ng.
        """
        fallback_result = {'search_context': query, 'specific_question': "", 'objects_vi': [], 'objects_en': []}
        prompt = f"""
        Analyze a Vietnamese user query for a video search system. Return ONLY a valid JSON object with: "search_context", "specific_question", "objects_vi", and "objects_en".

        Rules:
        - "search_context": A Vietnamese phrase for finding the scene.
        - "specific_question": The specific question. For KIS queries, this is an empty string "".
        - "objects_vi": A list of Vietnamese nouns/entities.
        - "objects_en": The English translation for EACH item in "objects_vi". The two lists must have the same length.

        Example (VQA):
        Query: "Trong video quay cáº£nh bá»¯a tiá»‡c, ngÆ°á»i phá»¥ ná»¯ máº·c vÃ¡y Ä‘á» Ä‘ang cáº§m ly mÃ u gÃ¬?"
        JSON: {{"search_context": "cáº£nh bá»¯a tiá»‡c cÃ³ ngÆ°á»i phá»¥ ná»¯ máº·c vÃ¡y Ä‘á»", "specific_question": "cÃ´ áº¥y Ä‘ang cáº§m ly mÃ u gÃ¬?", "objects_vi": ["bá»¯a tiá»‡c", "ngÆ°á»i phá»¥ ná»¯", "vÃ¡y Ä‘á»"], "objects_en": ["party", "woman", "red dress"]}}

        Query: "{query}"
        JSON:
        """
        try:
            response_content = self._openai_chat_completion([{"role": "user", "content": prompt}], is_json=True)
            result = json.loads(response_content)
            # Validate...
            if all(k in result for k in ['search_context', 'specific_question', 'objects_vi', 'objects_en']):
                return result
            return fallback_result
        except Exception as e:
            print(f"Lá»—i OpenAI enhance_query: {e}")
            return fallback_result

    def analyze_task_type(self, query: str) -> str:
        """PhÃ¢n loáº¡i truy váº¥n thÃ nh 'KIS', 'QNA', hoáº·c 'TRAKE'."""
        prompt = f"""
        Classify the Vietnamese query into "KIS", "QNA", or "TRAKE". Return ONLY the type as a single word.
        - "KIS": Looking for a single scene.
        - "QNA": Asking a question about a scene.
        - "TRAKE": Looking for a sequence of actions.
        Query: "{query}"
        Type:
        """
        try:
            response = self._openai_chat_completion([{"role": "user", "content": prompt}], is_json=False)
            task_type = response.strip().upper()
            if task_type in ["KIS", "QNA", "TRAKE"]:
                return task_type
            return "KIS" # Fallback an toÃ n
        except Exception as e:
            print(f"Lá»—i OpenAI analyze_task_type: {e}")
            return "KIS"

    def perform_vqa(self, image_path: str, question: str) -> Dict[str, any]:
        """
        Thá»±c hiá»‡n VQA sá»­ dá»¥ng GPT-4o.
        """
        base64_image = self._encode_image_to_base64(image_path)
        if not base64_image:
            return {"answer": "Lá»—i: KhÃ´ng thá»ƒ xá»­ lÃ½ áº£nh", "confidence": 0.0}

        prompt = f"""
        You are a Visual Question Answering assistant. Based on the provided image, answer the user's question.
        Return ONLY a valid JSON object with two keys: "answer" and "confidence".
        - "answer": A short, direct answer in Vietnamese.
        - "confidence": Your confidence in the answer, from 0.0 (very unsure) to 1.0 (certain).

        Question: "{question}"
        JSON:
        """
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"},
                    },
                ],
            }
        ]
        try:
            response_content = self._openai_chat_completion(messages, is_json=True, is_vision=True)
            result = json.loads(response_content)
            return {
                "answer": result.get("answer", "KhÃ´ng cÃ³ cÃ¢u tráº£ lá»i"),
                "confidence": float(result.get("confidence", 0.5))
            }
        except Exception as e:
            print(f"Lá»—i OpenAI perform_vqa: {e}")
            return {"answer": "Lá»—i xá»­ lÃ½ VQA", "confidence": 0.0}

    def decompose_trake_query(self, query: str) -> List[str]:
        """PhÃ¢n rÃ£ truy váº¥n TRAKE thÃ nh cÃ¡c bÆ°á»›c con."""
        prompt = f"""
        Decompose the Vietnamese query describing a sequence of actions into a JSON array of short, self-contained phrases. Return ONLY the JSON array.

        Example:
        Query: "TÃ¬m 4 khoáº£nh kháº¯c chÃ­nh khi váº­n Ä‘á»™ng viÃªn thá»±c hiá»‡n cÃº nháº£y: (1) giáº­m nháº£y, (2) bay qua xÃ , (3) tiáº¿p Ä‘áº¥t, (4) Ä‘á»©ng dáº­y."
        JSON: ["váº­n Ä‘á»™ng viÃªn giáº­m nháº£y", "váº­n Ä‘á»™ng viÃªn bay qua xÃ ", "váº­n Ä‘á»™ng viÃªn tiáº¿p Ä‘áº¥t", "váº­n Ä‘á»™ng viÃªn Ä‘á»©ng dáº­y"]

        Query: "{query}"
        JSON:
        """
        try:
            response_content = self._openai_chat_completion([{"role": "user", "content": prompt}], is_json=True)
            result = json.loads(response_content)
            if isinstance(result, list):
                return result
            return [query] # Fallback
        except Exception as e:
            print(f"Lá»—i OpenAI decompose_trake_query: {e}")
            return [query]