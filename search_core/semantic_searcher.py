# ==============================================================================
# SEMANTIC SEARCHER - PHI√äN B·∫¢N V5 (T·ªêI ∆ØU H√ìA & N√ÇNG C·∫§P T·ª™ B·∫¢N G·ªêC)
# ==============================================================================
import pandas as pd
import faiss
from sentence_transformers import SentenceTransformer, util
import numpy as np
import json
import re
import torch
from tqdm import tqdm
from typing import Dict, List, Optional, Any

from search_core.basic_searcher import BasicSearcher

class SemanticSearcher:
    def __init__(self, 
                 basic_searcher: BasicSearcher, 
                 device: str = "cuda"):
        # --- KH√îNG THAY ƒê·ªîI ---
        print("--- üß† Kh·ªüi t·∫°o SemanticSearcher (Reranking Engine) ---")
        self.device = device
        self.basic_searcher = basic_searcher
        
        print("   -> ƒêang t·∫£i m√¥ h√¨nh Bi-Encoder ti·∫øng Vi·ªát...")
        self.semantic_model = SentenceTransformer(
            'bkai-foundation-models/vietnamese-bi-encoder', 
            device=self.device
        )
        print("--- ‚úÖ T·∫£i model Bi-Encoder th√†nh c√¥ng! ---")

    def search(self, 
            query_text: str, 
            top_k_final: int, 
            top_k_retrieval: int, 
            precomputed_analysis: Dict[str, Any] = None
            ) -> List[Dict[str, Any]]:
        
        # --- LOG TH√îNG B√ÅO G·ªêC (GI·ªÆ NGUY√äN) ---
        print(f"\n--- B·∫Øt ƒë·∫ßu Semantic Search cho context: '{query_text}' ---")
        
        # --- B∆Ø·ªöC 1 (GI·ªÆ NGUY√äN) ---
        candidates = self.basic_searcher.search(query_text, top_k=top_k_retrieval)
        if not candidates:
            print("-> Kh√¥ng t√¨m th·∫•y ·ª©ng vi√™n n√†o.")
            return []

        enhanced_query = precomputed_analysis or {}
        
        rerank_keywords_en = enhanced_query.get('objects_en', [])
        rerank_context_vi = enhanced_query.get('search_context', query_text).lower().strip()
        
        # --- B∆Ø·ªöC 3: T√ÅI X·∫æP H·∫†NG (N√ÇNG C·∫§P) ---

        # --- 3a. M√£ h√≥a Context v√† B·ªëi c·∫£nh Keyframe (theo batch) ---
        context_vector = self.semantic_model.encode(rerank_context_vi, convert_to_tensor=True, device=self.device)
        
        # *** N√ÇNG C·∫§P 1: T·∫†O B·ªêI C·∫¢NH "S·∫†CH" T·ª™ C√ÅC C·ªòT CHUY√äN BI·ªÜT ***
        candidate_contexts = [
            (cand.get('transcript_text', '') + " " + cand.get('object_text', '')).strip() 
            for cand in candidates
        ]
        
        candidate_vectors = self.semantic_model.encode(
            candidate_contexts, # <-- S·ª≠ d·ª•ng context ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch
            convert_to_tensor=True, 
            device=self.device, 
            batch_size=128, 
            show_progress_bar=False
        )
        semantic_scores_tensor = util.pytorch_cos_sim(context_vector, candidate_vectors)[0]

        # --- 3b. M√£ h√≥a Object (theo batch) (GI·ªÆ NGUY√äN TO√ÄN B·ªò LOGIC G·ªêC) ---
        all_detected_objects = []
        cand_object_indices = []
        for cand in candidates:
            detected_objects_en_raw = cand.get('objects_detected', [])
            detected_objects_en = list(detected_objects_en_raw) if isinstance(detected_objects_en_raw, np.ndarray) else list(detected_objects_en_raw)
            start_index = len(all_detected_objects)
            all_detected_objects.extend(detected_objects_en)
            end_index = len(all_detected_objects)
            cand_object_indices.append((start_index, end_index))

        all_object_vectors = None
        if all_detected_objects:
            all_object_vectors = self.semantic_model.encode(
                all_detected_objects, 
                convert_to_tensor=True, 
                device=self.device, 
                batch_size=256, 
                show_progress_bar=False
            )

        query_object_vectors = None
        if rerank_keywords_en:
            query_object_vectors = self.semantic_model.encode(
                rerank_keywords_en, convert_to_tensor=True, device=self.device)

        # --- 3c. T√≠nh to√°n ƒëi·ªÉm cu·ªëi c√πng (GI·ªÆ NGUY√äN TO√ÄN B·ªò LOGIC G·ªêC) ---
        reranked_results = []
        for i, cand in enumerate(candidates):
            # T√≠nh Object Score
            object_score = 0.0
            start, end = cand_object_indices[i]
            if query_object_vectors is not None and start < end and all_object_vectors is not None:
                detected_object_vectors = all_object_vectors[start:end]
                cosine_scores = util.pytorch_cos_sim(query_object_vectors, detected_object_vectors)
                if cosine_scores.numel() > 0:
                    max_scores_per_query_obj = torch.max(cosine_scores, dim=1).values
                    object_score = torch.mean(max_scores_per_query_obj).item()

            # T√≠nh Semantic Score
            semantic_score = (semantic_scores_tensor[i].item() + 1) / 2
            
            original_clip_score = cand['clip_score'] # N·∫±m trong kho·∫£ng [-1, 1]
            # Chu·∫©n h√≥a ƒëi·ªÉm CLIP v·ªÅ [0, 1] ƒë·ªÉ c·ªông h∆∞·ªüng t·ªët h∆°n
            normalized_clip_score = (original_clip_score + 1) / 2
            
            # T√≠nh Final Score
            w_clip = precomputed_analysis.get('w_clip', 0.4)
            w_obj = precomputed_analysis.get('w_obj', 0.3)
            w_semantic = precomputed_analysis.get('w_semantic', 0.3)
            
            final_score = (w_clip * normalized_clip_score + 
                           w_obj * object_score + 
                           w_semantic * semantic_score)
            
            cand['final_score'] = final_score
            cand['scores'] = {'clip': normalized_clip_score, 'object': object_score, 'semantic': semantic_score}
            reranked_results.append(cand)

        # --- S·∫ÆP X·∫æP V√Ä TR·∫¢ V·ªÄ (GI·ªÆ NGUY√äN) ---
        reranked_results = sorted(reranked_results, key=lambda x: x['final_score'], reverse=True)
        
        # --- LOG TH√îNG B√ÅO G·ªêC (GI·ªÆ NGUY√äN) ---
        print(f"--- ‚úÖ T√°i x·∫øp h·∫°ng cho context '{query_text}' ho√†n t·∫•t! ---")
        
        return reranked_results[:top_k_final]