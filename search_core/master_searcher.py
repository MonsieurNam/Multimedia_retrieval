from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, Any, Optional
import os
import json

from tqdm import tqdm 
import google.generativeai as genai # V·∫´n c·∫ßn cho type hinting n·∫øu d√πng Gemini
from google.api_core import exceptions as google_exceptions

# Import c√°c module c·ªët l√µi c·ªßa h·ªá th·ªëng
from search_core.basic_searcher import BasicSearcher
from search_core.semantic_searcher import SemanticSearcher
from search_core.trake_solver import TRAKESolver
from search_core.gemini_text_handler import GeminiTextHandler
from search_core.openai_handler import OpenAIHandler
from search_core.task_analyzer import TaskType

class MasterSearcher:
    """
    L·ªõp ƒëi·ªÅu ph·ªëi ch√≠nh c·ªßa h·ªá th·ªëng t√¨m ki·∫øm (Hybrid AI Edition).
    N√≥ qu·∫£n l√Ω v√† ƒëi·ªÅu ph·ªëi c√°c AI Handler kh√°c nhau (Gemini cho text, OpenAI cho vision)
    ƒë·ªÉ gi·∫£i quy·∫øt c√°c lo·∫°i truy v·∫•n ph·ª©c t·∫°p.
    """

    def __init__(self, 
                 basic_searcher: BasicSearcher, 
                 gemini_api_key: Optional[str] = None,
                 openai_api_key: Optional[str] = None,
                 entities_path: str = None):
        """
        Kh·ªüi t·∫°o MasterSearcher v√† h·ªá sinh th√°i AI lai.

        Args:
            basic_searcher (BasicSearcher): Instance c·ªßa BasicSearcher ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o.
            gemini_api_key (Optional[str]): API key cho Google Gemini (d√πng cho text).
            openai_api_key (Optional[str]): API key cho OpenAI (d√πng cho vision/VQA).
        """
        print("--- üß† Kh·ªüi t·∫°o Master Searcher (Hybrid AI Edition) ---")
        
        self.semantic_searcher = SemanticSearcher(basic_searcher=basic_searcher)
        
        self.gemini_handler: Optional[GeminiTextHandler] = None
        self.openai_handler: Optional[OpenAIHandler] = None
        self.trake_solver: Optional[TRAKESolver] = None
        self.ai_enabled = False
        self.known_entities: set = set()
        
        if entities_path and os.path.exists(entities_path):
            try:
                print(f"--- üìö ƒêang t·∫£i T·ª´ ƒëi·ªÉn ƒê·ªëi t∆∞·ª£ng t·ª´: {entities_path} ---")
                with open(entities_path, 'r') as f:
                    entities_list = [entity.lower() for entity in json.load(f)]
                    self.known_entities = set(entities_list)
                print(f"--- ‚úÖ T·∫£i th√†nh c√¥ng {len(self.known_entities)} th·ª±c th·ªÉ ƒë√£ bi·∫øt. ---")
            except Exception as e:
                print(f"--- ‚ö†Ô∏è L·ªói khi t·∫£i T·ª´ ƒëi·ªÉn ƒê·ªëi t∆∞·ª£ng: {e}. T√≠nh nƒÉng Semantic Grounding s·∫Ω b·ªã v√¥ hi·ªáu h√≥a. ---")
                
        # --- Kh·ªüi t·∫°o v√† x√°c th·ª±c Gemini Handler cho c√°c t√°c v·ª• TEXT ---
        if gemini_api_key:
            try:
                self.gemini_handler = GeminiTextHandler(api_key=gemini_api_key)
                if self.known_entities and self.gemini_handler:
                    self.gemini_handler.load_known_entities(self.known_entities)
                self.ai_enabled = True # B·∫≠t c·ªù AI n·∫øu √≠t nh·∫•t m·ªôt handler ho·∫°t ƒë·ªông
            except Exception as e:
                print(f"--- ‚ö†Ô∏è L·ªói khi kh·ªüi t·∫°o Gemini Handler: {e}. C√°c t√≠nh nƒÉng text AI s·∫Ω b·ªã h·∫°n ch·∫ø. ---")

        # --- Kh·ªüi t·∫°o v√† x√°c th·ª±c OpenAI Handler cho c√°c t√°c v·ª• VISION ---
        if openai_api_key:
            try:
                self.openai_handler = OpenAIHandler(api_key=openai_api_key)
                if not self.openai_handler.check_api_health():
                    self.openai_handler = None # V√¥ hi·ªáu h√≥a n·∫øu health check th·∫•t b·∫°i
                else:
                    self.ai_enabled = True
            except Exception as e:
                print(f"--- ‚ö†Ô∏è L·ªói khi kh·ªüi t·∫°o OpenAI Handler: {e}. C√°c t√≠nh nƒÉng vision AI s·∫Ω b·ªã h·∫°n ch·∫ø. ---")
        
        # --- Kh·ªüi t·∫°o c√°c Solver ph·ª©c t·∫°p n·∫øu c√°c handler c·∫ßn thi·∫øt ƒë√£ s·∫µn s√†ng ---
        if self.gemini_handler:
            # TRAKE Solver ch·ªâ c·∫ßn text handler ƒë·ªÉ ph√¢n r√£ truy v·∫•n
            self.trake_solver = TRAKESolver(ai_handler=self.gemini_handler)
    

        print(f"--- ‚úÖ Master Searcher ƒë√£ s·∫µn s√†ng! (AI Enabled: {self.ai_enabled}) ---")

    def search(self, query: str, config: Dict[str, Any]) -> Dict[str, Any]:
        """
        H√†m t√¨m ki·∫øm ch√≠nh, nh·∫≠n m·ªôt dictionary config ƒë·ªÉ t√πy ch·ªânh h√†nh vi.
        *** PHI√äN B·∫¢N HO√ÄN THI·ªÜN T√çCH H·ª¢P ƒê·∫¶Y ƒê·ª¶ CONFIG T·ª™ UI ***
        """
        # --- B∆∞·ªõc 1: Gi·∫£i n√©n to√†n b·ªô Config t·ª´ UI v·ªõi gi√° tr·ªã m·∫∑c ƒë·ªãnh an to√†n ---
        top_k_final = int(config.get('top_k_final', 12))
        
        # KIS config
        kis_retrieval = int(config.get('kis_retrieval', 100))
        
        # VQA config
        vqa_candidates_to_rank = int(config.get('vqa_candidates', 8))
        vqa_retrieval = int(config.get('vqa_retrieval', 200))

        # TRAKE config
        trake_candidates_per_step = int(config.get('trake_candidates_per_step', 15))
        trake_max_sequences = int(config.get('trake_max_sequences', 50))

        # Track-VQA config
        w_clip = config.get('w_clip', 0.4)
        w_obj = config.get('w_obj', 0.3)
        w_semantic = config.get('w_semantic', 0.3)
        # --- B∆∞·ªõc 2: Ph√¢n t√≠ch Truy v·∫•n ---
        query_analysis = {}
        task_type = TaskType.KIS
        if self.ai_enabled and self.gemini_handler:
            print("--- ‚ú® B·∫Øt ƒë·∫ßu ph√¢n t√≠ch truy v·∫•n b·∫±ng Gemini Text Handler... ---")
            query_analysis = self.gemini_handler.analyze_query_fully(query)
            
            original_objects = query_analysis.get('objects_en', [])
            if original_objects: # Ch·ªâ g·ªçi API n·∫øu c√≥ object ƒë·ªÉ x·ª≠ l√Ω
                grounded_objects = self.gemini_handler.perform_semantic_grounding(original_objects)
                
                if original_objects != grounded_objects:
                     print(f"--- üß† Semantic Grounding: {original_objects} -> {grounded_objects} ---")
                
                query_analysis['objects_en'] = grounded_objects
                
            task_type_str = query_analysis.get('task_type', 'KIS').upper()
            try:
                task_type = TaskType[task_type_str]
            except KeyError:
                task_type = TaskType.KIS
        
        print(f"--- ƒê√£ ph√¢n lo·∫°i truy v·∫•n l√†: {task_type.value} ---")

        final_results = []
        query_analysis['w_clip'] = w_clip
        query_analysis['w_obj'] = w_obj
        query_analysis['w_semantic'] = w_semantic
        search_context = query_analysis.get('search_context', query)

        # --- B∆∞·ªõc 3: Kh·ªëi ƒêi·ªÅu ph·ªëi Logic (C·∫≠p nh·∫≠t ƒë·ªÉ truy·ªÅn Config) ---
        if task_type == TaskType.TRAKE:
            if self.trake_solver:
                sub_queries = self.trake_solver.decompose_query(query)
                final_results = self.trake_solver.find_sequences(
                    sub_queries, 
                    self.semantic_searcher, 
                    top_k_per_step=trake_candidates_per_step,
                    max_sequences=trake_max_sequences
                )
            else:
                task_type = TaskType.KIS # Fallback

        elif task_type == TaskType.QNA:
            if self.openai_handler:
                # 1. L·∫•y ra c√°c ·ª©ng vi√™n b·ªëi c·∫£nh (kh√¥ng ƒë·ªïi)
                candidates = self.semantic_searcher.search(
                    query_text=search_context,
                    precomputed_analysis=query_analysis,
                    # L·∫•y ra nhi·ªÅu ·ª©ng vi√™n h∆°n ·ªü b∆∞·ªõc n√†y, v√¨ VQA s·∫Ω l·ªçc l·∫°i
                    top_k_final=vqa_retrieval,
                    top_k_retrieval=vqa_retrieval
                )

                if not candidates:
                    final_results = []
                else:
                    # Ch·ªçn ra s·ªë l∆∞·ª£ng ·ª©ng vi√™n h√†ng ƒë·∫ßu ƒë·ªÉ ph√¢n t√≠ch VQA
                    candidates_for_vqa = candidates[:vqa_candidates_to_rank]
                    
                    specific_question = query_analysis.get('specific_question', query)
                    vqa_enhanced_candidates = []
                    
                    print(f"--- üí¨ B·∫Øt ƒë·∫ßu Qu√©t VQA song song tr√™n {len(candidates_for_vqa)} ·ª©ng vi√™n... ---")

                    # 2. S·ª≠ d·ª•ng ThreadPoolExecutor ƒë·ªÉ x·ª≠ l√Ω song song
                    with ThreadPoolExecutor(max_workers=8) as executor: # S·ªë worker c√≥ th·ªÉ tinh ch·ªânh
                        
                        # T·∫°o m·ªôt future cho m·ªói candidate
                        future_to_candidate = {
                            executor.submit(
                                self.openai_handler.perform_vqa, 
                                image_path=cand['keyframe_path'], 
                                question=specific_question, 
                                context_text=cand.get('transcript_text', '')
                            ): cand 
                            for cand in candidates_for_vqa
                        }
                        
                        # Thu th·∫≠p k·∫øt qu·∫£ khi ch√∫ng ho√†n th√†nh
                        for future in tqdm(as_completed(future_to_candidate), total=len(candidates_for_vqa), desc="   -> VQA Progress"):
                            cand = future_to_candidate[future]
                            try:
                                vqa_result = future.result()
                                
                                new_cand = cand.copy()
                                new_cand['answer'] = vqa_result['answer']
                                
                                # T√≠nh ƒëi·ªÉm k·∫øt h·ª£p
                                search_score = new_cand.get('final_score', 0)
                                vqa_confidence = vqa_result.get('confidence', 0)
                                
                                # C√¥ng th·ª©c ƒëi·ªÉm m·ªõi c√≥ tr·ªçng s·ªë ƒë·ªÉ c√¢n b·∫±ng
                                # w_search = 0.6
                                # w_vqa_conf = 0.4
                                # new_cand['final_score'] = (w_search * search_score) + (w_vqa_conf * vqa_confidence)
                                new_cand['final_score'] = search_score * vqa_confidence # Gi·ªØ c√¥ng th·ª©c c≈© cho ƒë∆°n gi·∫£n

                                # L∆∞u l·∫°i ƒëi·ªÉm th√†nh ph·∫ßn ƒë·ªÉ hi·ªÉn th·ªã
                                new_cand['scores'] = new_cand.get('scores', {})
                                new_cand['scores']['search_score'] = search_score
                                new_cand['scores']['vqa_confidence'] = vqa_confidence
                                
                                vqa_enhanced_candidates.append(new_cand)
                                
                            except Exception as exc:
                                print(f"--- ‚ùå L·ªói khi x·ª≠ l√Ω VQA cho keyframe {cand.get('keyframe_id')}: {exc} ---")
                    
                    # 3. S·∫Øp x·∫øp l·∫°i danh s√°ch cu·ªëi c√πng d·ª±a tr√™n ƒëi·ªÉm s·ªë ƒë√£ k·∫øt h·ª£p
                    if vqa_enhanced_candidates:
                        final_results = sorted(vqa_enhanced_candidates, key=lambda x: x['final_score'], reverse=True)
                    else:
                        final_results = []
            else:
                print("--- ‚ö†Ô∏è OpenAI (VQA) handler ch∆∞a ƒë∆∞·ª£c k√≠ch ho·∫°t. Fallback v·ªÅ KIS. ---")
                task_type = TaskType.KIS
                final_results = [] # Reset final_results ƒë·ªÉ ch·∫°y kh·ªëi KIS ti·∫øp theo

        if not final_results or task_type == TaskType.KIS:
            final_results = self.semantic_searcher.search(
                query_text=search_context,
                precomputed_analysis=query_analysis,
                top_k_final=top_k_final, 
                top_k_retrieval=kis_retrieval
            )
        return {
            "task_type": task_type,
            "results": final_results,
            "query_analysis": query_analysis
        }