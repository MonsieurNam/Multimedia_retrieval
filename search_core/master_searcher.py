from typing import Dict, Any, Optional
import os
import json
import google.generativeai as genai # V·∫´n c·∫ßn cho type hinting n·∫øu d√πng Gemini
from google.api_core import exceptions as google_exceptions

# Import c√°c module c·ªët l√µi c·ªßa h·ªá th·ªëng
from search_core.basic_searcher import BasicSearcher
from search_core.semantic_searcher import SemanticSearcher
from search_core.trake_solver import TRAKESolver
from search_core.track_vqa_solver import TrackVQASolver
from search_core.gemini_text_handler import GeminiTextHandler
from search_core.openai_handler import OpenAIHandler
from search_core.task_analyzer import TaskType

class MasterSearcher:
    """
    L·ªõp ƒëi·ªÅu ph·ªëi ch√≠nh c·ªßa h·ªá th·ªëng t√¨m ki·∫øm (Hybrid AI Edition).
    N√≥ qu·∫£n l√Ω v√† ƒëi·ªÅu ph·ªëi c√°c AI Handler kh√°c nhau (Gemini cho text, OpenAI cho vision)
    ƒë·ªÉ gi·∫£i quy·∫øt c√°c lo·∫°i truy v·∫•n ph·ª©c t·∫°p.
    """

    def __init__(self, 
                 basic_searcher: BasicSearcher, 
                 gemini_api_key: Optional[str] = None,
                 openai_api_key: Optional[str] = None,
                 entities_path: str = None):
        """
        Kh·ªüi t·∫°o MasterSearcher v√† h·ªá sinh th√°i AI lai.

        Args:
            basic_searcher (BasicSearcher): Instance c·ªßa BasicSearcher ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o.
            gemini_api_key (Optional[str]): API key cho Google Gemini (d√πng cho text).
            openai_api_key (Optional[str]): API key cho OpenAI (d√πng cho vision/VQA).
        """
        print("--- üß† Kh·ªüi t·∫°o Master Searcher (Hybrid AI Edition) ---")
        
        self.semantic_searcher = SemanticSearcher(basic_searcher=basic_searcher)
        
        self.gemini_handler: Optional[GeminiTextHandler] = None
        self.openai_handler: Optional[OpenAIHandler] = None
        self.trake_solver: Optional[TRAKESolver] = None
        self.track_vqa_solver: Optional[TrackVQASolver] = None
        self.ai_enabled = False
        self.known_entities: set = set()
        
        if entities_path and os.path.exists(entities_path):
            try:
                print(f"--- üìö ƒêang t·∫£i T·ª´ ƒëi·ªÉn ƒê·ªëi t∆∞·ª£ng t·ª´: {entities_path} ---")
                with open(entities_path, 'r') as f:
                    entities_list = [entity.lower() for entity in json.load(f)]
                    self.known_entities = set(entities_list)
                print(f"--- ‚úÖ T·∫£i th√†nh c√¥ng {len(self.known_entities)} th·ª±c th·ªÉ ƒë√£ bi·∫øt. ---")
            except Exception as e:
                print(f"--- ‚ö†Ô∏è L·ªói khi t·∫£i T·ª´ ƒëi·ªÉn ƒê·ªëi t∆∞·ª£ng: {e}. T√≠nh nƒÉng Semantic Grounding s·∫Ω b·ªã v√¥ hi·ªáu h√≥a. ---")
                
        # --- Kh·ªüi t·∫°o v√† x√°c th·ª±c Gemini Handler cho c√°c t√°c v·ª• TEXT ---
        if gemini_api_key:
            try:
                self.gemini_handler = GeminiTextHandler(api_key=gemini_api_key)
                if self.known_entities and self.gemini_handler:
                    self.gemini_handler.load_known_entities(self.known_entities)
                self.ai_enabled = True # B·∫≠t c·ªù AI n·∫øu √≠t nh·∫•t m·ªôt handler ho·∫°t ƒë·ªông
            except Exception as e:
                print(f"--- ‚ö†Ô∏è L·ªói khi kh·ªüi t·∫°o Gemini Handler: {e}. C√°c t√≠nh nƒÉng text AI s·∫Ω b·ªã h·∫°n ch·∫ø. ---")

        # --- Kh·ªüi t·∫°o v√† x√°c th·ª±c OpenAI Handler cho c√°c t√°c v·ª• VISION ---
        if openai_api_key:
            try:
                self.openai_handler = OpenAIHandler(api_key=openai_api_key)
                if not self.openai_handler.check_api_health():
                    self.openai_handler = None # V√¥ hi·ªáu h√≥a n·∫øu health check th·∫•t b·∫°i
                else:
                    self.ai_enabled = True
            except Exception as e:
                print(f"--- ‚ö†Ô∏è L·ªói khi kh·ªüi t·∫°o OpenAI Handler: {e}. C√°c t√≠nh nƒÉng vision AI s·∫Ω b·ªã h·∫°n ch·∫ø. ---")
        
        # --- Kh·ªüi t·∫°o c√°c Solver ph·ª©c t·∫°p n·∫øu c√°c handler c·∫ßn thi·∫øt ƒë√£ s·∫µn s√†ng ---
        if self.gemini_handler:
            # TRAKE Solver ch·ªâ c·∫ßn text handler ƒë·ªÉ ph√¢n r√£ truy v·∫•n
            self.trake_solver = TRAKESolver(ai_handler=self.gemini_handler)
        
        if self.gemini_handler and self.openai_handler:
            # TrackVQASolver c·∫ßn c·∫£ hai: text ƒë·ªÉ ph√¢n t√≠ch, vision ƒë·ªÉ h·ªèi ƒë√°p
            self.track_vqa_solver = TrackVQASolver(
                text_handler=self.gemini_handler, 
                vision_handler=self.openai_handler,
                semantic_searcher=self.semantic_searcher
            )

        print(f"--- ‚úÖ Master Searcher ƒë√£ s·∫µn s√†ng! (AI Enabled: {self.ai_enabled}) ---")

    def search(self, query: str, config: Dict[str, Any]) -> Dict[str, Any]:
        """
        H√†m t√¨m ki·∫øm ch√≠nh, nh·∫≠n m·ªôt dictionary config ƒë·ªÉ t√πy ch·ªânh h√†nh vi.
        *** PHI√äN B·∫¢N HO√ÄN THI·ªÜN T√çCH H·ª¢P ƒê·∫¶Y ƒê·ª¶ CONFIG T·ª™ UI ***
        """
        # --- B∆∞·ªõc 1: Gi·∫£i n√©n to√†n b·ªô Config t·ª´ UI v·ªõi gi√° tr·ªã m·∫∑c ƒë·ªãnh an to√†n ---
        top_k_final = int(config.get('top_k_final', 12))
        
        # KIS config
        kis_retrieval = int(config.get('kis_retrieval', 100))
        
        # VQA config
        vqa_candidates_to_rank = int(config.get('vqa_candidates', 8))
        vqa_retrieval = int(config.get('vqa_retrieval', 200))

        # TRAKE config
        trake_candidates_per_step = int(config.get('trake_candidates_per_step', 15))
        trake_max_sequences = int(config.get('trake_max_sequences', 50))

        # Track-VQA config
        track_vqa_retrieval = int(config.get('track_vqa_retrieval', 200))
        track_vqa_candidates_to_analyze = int(config.get('track_vqa_candidates', 20))

        # --- B∆∞·ªõc 2: Ph√¢n t√≠ch Truy v·∫•n ---
        query_analysis = {}
        task_type = TaskType.KIS
        if self.ai_enabled and self.gemini_handler:
            print("--- ‚ú® B·∫Øt ƒë·∫ßu ph√¢n t√≠ch truy v·∫•n b·∫±ng Gemini Text Handler... ---")
            query_analysis = self.gemini_handler.enhance_query(query)
            original_objects = query_analysis.get('objects_en', [])
            if original_objects: # Ch·ªâ g·ªçi API n·∫øu c√≥ object ƒë·ªÉ x·ª≠ l√Ω
                grounded_objects = self.gemini_handler.perform_semantic_grounding(original_objects)
                
                if original_objects != grounded_objects:
                     print(f"--- üß† Semantic Grounding: {original_objects} -> {grounded_objects} ---")
                
                query_analysis['objects_en'] = grounded_objects
                
            task_type_str = self.gemini_handler.analyze_task_type(query)
            try:
                task_type = TaskType[task_type_str]
            except KeyError:
                task_type = TaskType.KIS
        
        print(f"--- ƒê√£ ph√¢n lo·∫°i truy v·∫•n l√†: {task_type.value} ---")

        final_results = []
        search_context = query_analysis.get('search_context', query)

        # --- B∆∞·ªõc 3: Kh·ªëi ƒêi·ªÅu ph·ªëi Logic (C·∫≠p nh·∫≠t ƒë·ªÉ truy·ªÅn Config) ---

        if task_type == TaskType.TRACK_VQA:
            if self.track_vqa_solver:
                track_vqa_result = self.track_vqa_solver.solve(
                    query_analysis,
                    candidates_to_retrieve=track_vqa_retrieval,
                    candidates_to_analyze=track_vqa_candidates_to_analyze
                )
                
                evidence_frames = track_vqa_result.get("evidence_frames", [])
                for frame in evidence_frames:   
                    path = frame.get('keyframe_path')
                    print(f"DEBUG: Checking path '{path}'... Found: {path}") # <-- TH√äM D√íNG N√ÄY
                # --- LOGIC "L√ÄM PH·∫≤NG" D·ªÆ LI·ªÜU B·∫ÆT ƒê·∫¶U T·ª™ ƒê√ÇY ---

                # 1. T·∫°o m·ªôt danh s√°ch c√°c ƒë∆∞·ªùng d·∫´n ·∫£nh (ch·ªâ string)
                evidence_paths = [
                    frame.get('keyframe_path') 
                    for frame in evidence_frames 
                    if frame.get('keyframe_path') and os.path.isfile(frame.get('keyframe_path'))
                ]
                
                # 2. T·∫°o m·ªôt danh s√°ch c√°c ch√∫ th√≠ch (ch·ªâ string)
                evidence_captions = [
                    f"{frame.get('video_id', 'N/A')} @{frame.get('timestamp', 0):.1f}s"
                    for frame in evidence_frames
                    if frame.get('keyframe_path') and os.path.isfile(frame.get('keyframe_path'))
                ]

                # 3. T·∫°o m·ªôt "k·∫øt qu·∫£ ·∫£o" duy nh·∫•t ch·ª©a d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l√†m ph·∫≥ng
                final_results = [{
                    "is_aggregated_result": True,
                    "final_answer": track_vqa_result.get("final_answer", "L·ªói t·ªïng h·ª£p k·∫øt qu·∫£."),
                    
                    # Thay th·∫ø list of dicts ph·ª©c t·∫°p b·∫±ng c√°c list of strings ƒë∆°n gi·∫£n
                    "evidence_paths": evidence_paths, 
                    "evidence_captions": evidence_captions,
                    
                    # Cung c·∫•p keyframe ƒë·∫ßu ti√™n ƒë·ªÉ gallery c√≥ ·∫£nh ƒë·∫°i di·ªán.
                    # ƒê·∫£m b·∫£o n√≥ l√† None n·∫øu kh√¥ng c√≥ b·∫±ng ch·ª©ng n√†o h·ª£p l·ªá.
                    "keyframe_path": evidence_paths[0] if evidence_paths else None,
                    
                    # Cung c·∫•p c√°c th√¥ng tin gi·∫£ ƒë·ªÉ c√°c h√†m kh√°c kh√¥ng b·ªã l·ªói
                    "video_id": "T·ªïng h·ª£p",
                    "timestamp": 0.0,
                    "final_score": 1.0, # ƒêi·ªÉm cao nh·∫•t v√¨ ƒë√¢y l√† k·∫øt qu·∫£ cu·ªëi c√πng
                    "scores": {}
                }]
            else:
                print("--- ‚ö†Ô∏è TrackVQA handler ch∆∞a ƒë∆∞·ª£c k√≠ch ho·∫°t. Fallback v·ªÅ KIS. ---")
                task_type = TaskType.KIS

        if task_type == TaskType.TRAKE:
            if self.trake_solver:
                sub_queries = self.trake_solver.decompose_query(query)
                final_results = self.trake_solver.find_sequences(
                    sub_queries, 
                    self.semantic_searcher, 
                    top_k_per_step=trake_candidates_per_step,
                    max_sequences=trake_max_sequences
                )
            else:
                task_type = TaskType.KIS # Fallback

        if task_type == TaskType.QNA:
            if self.openai_handler:
                candidates = self.semantic_searcher.search(
                    query_text=search_context,
                    precomputed_analysis=query_analysis,
                    top_k_final=vqa_candidates_to_rank,
                    top_k_retrieval=vqa_retrieval
                )
            specific_question = query_analysis.get('specific_question', query)
            vqa_enhanced_candidates = []
            for cand in candidates:
                vqa_result = self.openai_handler.perform_vqa(cand['keyframe_path'], specific_question)
                new_cand = cand.copy()
                new_cand['answer'] = vqa_result['answer']
                search_score, vqa_confidence = new_cand['final_score'], vqa_result['confidence']
                new_cand['final_score'] = search_score * vqa_confidence
                new_cand['scores']['search_score'] = search_score
                new_cand['scores']['vqa_confidence'] = vqa_confidence
                vqa_enhanced_candidates.append(new_cand)
            final_results = sorted(vqa_enhanced_candidates, key=lambda x: x['final_score'], reverse=True)

        if task_type == TaskType.KIS: # B·∫Øt c√°c tr∆∞·ªùng h·ª£p KIS g·ªëc v√† c√°c fallback
            final_results = self.semantic_searcher.search(
                query_text=search_context,
                precomputed_analysis=query_analysis,
                top_k_final=top_k_final, 
                top_k_retrieval=kis_retrieval
            )
        return {
            "task_type": task_type,
            "results": final_results,
            "query_analysis": query_analysis
        }